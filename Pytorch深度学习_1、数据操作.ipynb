{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch深度学习-1、数据操作.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPF2MK5lUOEMP6KyQIwN3c0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GzpTez0514/-/blob/main/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1%E3%80%81%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LEM0ZEcvhWt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "x = torch.arange(12)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "# 张量中元素的个数\n",
        "print(x.numel())\n",
        "X = x.reshape(3, 4)\n",
        "print(X)\n",
        "\n",
        "# 形状为（2， 3， 4）的张量，元素全为0\n",
        "a = torch.zeros((2, 3, 4))\n",
        "print(a)\n",
        "\n",
        "# 形状为(2, 3, 4)的张量，元素全为1\n",
        "b = torch.ones((2, 3, 4))\n",
        "print(b)\n",
        "\n",
        "# 形状为(3, 4)的张量，每个元素都从均值为0、标准差为1的正态分布中随机采样\n",
        "c = torch.randn(3, 4)\n",
        "print(c)\n",
        "\n",
        "# 最外层的列表对应于轴0，内层的列表对应于轴1\n",
        "d = torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# 运算符\n",
        "x = torch.tensor([1.0, 2, 4, 8])\n",
        "y = torch.tensor([2, 2, 2, 2])\n",
        "print(x + y)\n",
        "print(x - y)\n",
        "print(x * y)\n",
        "print(x / y)\n",
        "print(x ** y)\n",
        "# 指数运算\n",
        "print(torch.exp(x))\n",
        "\n",
        "# 对张量进行纵向和横向合并\n",
        "X = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
        "Y = torch.tensor([[2.0, 1, 4, 3], \n",
        "          [1, 2, 3, 4],\n",
        "          [4, 3, 2, 1]])\n",
        "\n",
        "print(torch.cat((X, Y), axis=0))\n",
        "print(torch.cat((X, Y), dim=0))\n",
        "print(torch.cat((X, Y), axis=1))\n",
        "print(X == Y)\n",
        "# 对张量中所有的元素求和\n",
        "print(X.sum())  # tensor(66.)"
      ],
      "metadata": {
        "id": "Uv5rbHpLwKLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 广播机制\n",
        "import torch\n",
        "a = torch.arange(3).reshape(3, 1)\n",
        "b = torch.arange(2).reshape(1, 2)\n",
        "print(a)\n",
        "print(b)\n",
        "# 将两个矩阵广播为一个更大的3*2矩阵,矩阵a将复制列，矩阵b将复制行，然后再按元素相加\n",
        "print(a + b)"
      ],
      "metadata": {
        "id": "n2aAHYfijQ4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 索引和切片\n",
        "import torch\n",
        "X = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
        "Y = torch.tensor([[2.0, 1, 4 ,3],\n",
        "          [1, 2, 3, 4], \n",
        "          [4, 3, 2, 1]])\n",
        "print(X)\n",
        "print(Y)\n",
        "# 用[-1]选择最后一个元素\n",
        "print(X[-1])\n",
        "# 用[1:3]选择第二个和第三个元素\n",
        "print(X[1:3])\n",
        "X[1, 2] = 9\n",
        "print(X)\n",
        "X[0:2, :] = 12\n",
        "print(X)"
      ],
      "metadata": {
        "id": "UE5Pmpvfj8pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 节省内存\n",
        "import torch\n",
        "X = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
        "Y = torch.tensor([[2.0, 1, 4, 3],\n",
        "          [1, 2, 3, 4],\n",
        "          [4, 3, 2, 1]])\n",
        "\n",
        "# 如果我们用Y = X + Y，我们将取消引用Y指向的张量，而是指向新分配的内存处的张量。\n",
        "before = id(Y)\n",
        "print(before)  # 140439963779152\n",
        "Y = Y + X\n",
        "print(id(Y))  # 140439963779920\n",
        "\n",
        "# 原地执行这些更新,不分配新的内存\n",
        "Z = torch.zeros_like(Y)\n",
        "print('id(Z):', id(Z))  # 140439963626672\n",
        "Z[:] = X + Y\n",
        "print('id(Z):', id(Z))  # 140439963626672"
      ],
      "metadata": {
        "id": "fBX7StlsmkAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypeAlias\n",
        "# 转换为其他Python对象\n",
        "import torch\n",
        "import numpy as np\n",
        "A = X.numpy()\n",
        "B = torch.tensor(A)\n",
        "print(type(A))\n",
        "print(type(B))\n",
        "\n",
        "a = torch.tensor([3.5])\n",
        "print(a)\n",
        "print(a.item())\n",
        "print(float(a))\n",
        "print(int(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8qhaWxQrfqa",
        "outputId": "943661bf-679f-4988-bb15-9416ae8a5f3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'>\n",
            "tensor([3.5000])\n",
            "3.5\n",
            "3.5\n",
            "3\n"
          ]
        }
      ]
    }
  ]
}