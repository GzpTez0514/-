{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch深度学习08.Pytorch实现反向传播",
      "provenance": [],
      "authorship_tag": "ABX9TyP9F+GHVAaNmZQSHAfnWAsV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GzpTez0514/-/blob/main/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A008_Pytorch%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yURSUPbBN3j1",
        "outputId": "92ed9f35-2c8b-4223-9d1c-fdeaeb32557a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor(2.),)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "X = torch.tensor(1., requires_grad=True) # requires_grad 表示允许对X进行梯度计算\n",
        "y = X ** 2\n",
        "\n",
        "grad = torch.autograd.grad(y, X) # 这里返回的是在函数y = X ** 2上，X = 1时的导数值\n",
        "print(grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 对于单层神经网络，autograd.grad会非常有效。但深层神经网络就不太适合使用grad函数了\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "torch.manual_seed(420)\n",
        "X = torch.rand((500, 20), dtype=torch.float32) * 100\n",
        "y = torch.randint(low=0, high=3, size=(500, 1), dtype=torch.float32)\n",
        "\n",
        "# 定义神经网络的架构\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, in_features=10, out_features=2):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(in_features, 13, bias=True)\n",
        "    self.linear2 = nn.Linear(13, 8, bias=True)\n",
        "    self.output = nn.Linear(8, out_features, bias=True)\n",
        "    \n",
        "  def forward(self, X):\n",
        "    z1 = self.linear1(X)\n",
        "    sigma1 = torch.relu(z1)\n",
        "    z2 = self.linear2(sigma1)\n",
        "    sigma2 = torch.sigmoid(z2)\n",
        "    z3 = self.output(sigma2)\n",
        "  # sigma3 = F.softmax(z3, dim=1)\n",
        "    return z3\n",
        "\n",
        "input_ = X.shape[1] # 特征的数目\n",
        "output_ = len(y.unique()) # 分类的数目\n",
        "\n",
        "# 实例化神经网络类\n",
        "torch.manual_seed(420)\n",
        "net = Model(in_features=input_, out_features=output_)\n",
        "# 正向传播\n",
        "zhat = net.forward(X)\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 对于打包好的CrossEntropyLoss而言，只需要输入zhat\n",
        "loss = criterion(zhat, y.reshape(500).long())\n",
        "print(loss)\n",
        "print(net.linear1.weight.grad) # 不会返回任何值\n",
        "# 反向传播，backward是任意损失函数类都可以调用的方法，对任意损失函数，backward都会求解其中全部w的梯度\n",
        "loss.backward()\n",
        "print(net.linear1.weight.grad) # 返回响应的梯度\n",
        "\n",
        "# 与可以重复进行的正向传播不同，一次正向传播后，反向传播只能进行一次\n",
        "# 如果希望可以重复进行反向传播，可以在第一次进行反向传播的时候加上参数retain_graph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMNl-ATpPrjx",
        "outputId": "ef733282-4b21-4eee-c9c4-b5d83e1dc88d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
            "None\n",
            "tensor([[ 3.3727e-04,  8.3354e-05,  4.0867e-04,  4.3058e-05,  1.4551e-04,\n",
            "          6.5092e-05,  3.7088e-04,  2.8794e-04,  1.0495e-04,  4.7446e-05,\n",
            "          8.8153e-05,  1.6899e-04,  1.0251e-04,  3.6197e-04,  1.2129e-04,\n",
            "          7.2405e-05,  1.4479e-04,  4.9114e-06,  1.0770e-04,  9.5156e-05],\n",
            "        [ 8.2042e-03,  2.1974e-02,  2.1073e-02,  1.3896e-02,  2.2161e-02,\n",
            "          1.5936e-02,  1.6537e-02,  2.0259e-02,  1.9655e-02,  1.4728e-02,\n",
            "          1.9212e-02,  2.0086e-02,  1.8295e-02,  8.4132e-03,  1.8036e-02,\n",
            "          1.9979e-02,  2.0966e-02,  2.4730e-02,  9.3876e-03,  1.7475e-02],\n",
            "        [ 9.1603e-03,  2.4275e-02,  2.3446e-02,  2.0096e-02,  2.5360e-02,\n",
            "          1.7406e-02,  3.2555e-02,  2.2461e-02,  3.6793e-03,  2.7445e-02,\n",
            "          2.1181e-02,  2.7724e-02,  1.7115e-02,  1.6943e-02,  1.7249e-02,\n",
            "          3.3173e-02,  1.5115e-02,  3.0874e-02,  1.8391e-02,  2.4201e-02],\n",
            "        [-2.8595e-04,  1.2968e-03,  1.3652e-03, -5.6692e-05, -1.7480e-03,\n",
            "         -2.6459e-03,  3.7307e-04, -2.7976e-03,  1.7848e-03, -9.9289e-04,\n",
            "         -3.3944e-04,  2.2783e-04,  1.2076e-03, -3.2906e-04,  5.4641e-04,\n",
            "         -2.8959e-03, -2.7890e-03, -3.0774e-03, -3.8981e-03, -6.0863e-03],\n",
            "        [ 1.5692e-03,  1.3161e-03, -9.0900e-04, -1.0158e-03, -4.9426e-03,\n",
            "          1.3061e-03, -6.8428e-03, -1.0955e-02,  4.2490e-03, -9.7841e-03,\n",
            "         -3.5231e-03, -6.9716e-03,  1.0742e-02,  2.9732e-03, -2.2283e-03,\n",
            "         -4.3101e-03, -1.2823e-03, -6.0040e-03, -1.5857e-03, -3.2208e-03],\n",
            "        [-2.3456e-03,  3.0270e-04, -9.7571e-04, -1.7812e-03, -1.9554e-03,\n",
            "          4.7728e-04, -7.5906e-04, -9.3554e-04, -8.6828e-04, -4.9501e-04,\n",
            "         -3.2291e-03, -2.6119e-03, -9.4872e-04, -1.3638e-03, -1.7115e-03,\n",
            "         -9.1220e-04, -1.0843e-03, -8.5492e-04,  1.5598e-04, -2.5193e-03],\n",
            "        [-1.8459e-02, -2.0009e-02, -1.3430e-02, -1.5675e-02, -1.3660e-02,\n",
            "         -1.4804e-02, -8.0083e-03, -2.0027e-02, -2.9173e-02,  7.5748e-03,\n",
            "         -1.8572e-02, -5.4350e-03, -3.2866e-02, -9.2504e-03, -1.8047e-02,\n",
            "         -9.1732e-03, -1.6036e-02, -1.4584e-02, -8.9602e-03,  1.7230e-03],\n",
            "        [ 9.5595e-04, -2.0620e-02, -2.6421e-02, -1.9139e-02, -2.5206e-02,\n",
            "         -9.0114e-03, -2.5945e-02, -1.8858e-02, -3.5860e-03, -3.2187e-02,\n",
            "         -1.8400e-02, -1.8522e-02, -1.1765e-02, -1.5216e-02, -8.4282e-03,\n",
            "         -3.0337e-02, -1.1364e-02, -2.9159e-02, -5.1049e-03, -2.6377e-02],\n",
            "        [ 3.7390e-03, -1.3553e-03, -2.2382e-03,  2.2693e-03, -1.4464e-03,\n",
            "         -2.4332e-03, -3.7881e-03,  7.3999e-04,  1.2527e-02, -1.9007e-03,\n",
            "          7.8561e-03, -9.5000e-03,  9.1147e-03, -2.2882e-03,  5.5781e-03,\n",
            "         -5.0263e-03,  4.8214e-03,  2.0531e-03,  4.1112e-04, -2.4565e-03],\n",
            "        [ 2.4338e-03,  2.9046e-03, -1.0326e-02, -4.4877e-03, -8.1686e-05,\n",
            "         -3.0232e-03,  3.2874e-03, -7.5255e-03, -1.0000e-02,  3.9967e-03,\n",
            "          6.3736e-03, -2.3521e-03, -3.5956e-03, -4.8027e-03, -2.7523e-03,\n",
            "          1.6497e-03, -1.3330e-03,  3.1406e-03,  4.9480e-03, -1.5097e-03],\n",
            "        [-7.3584e-04,  9.5657e-04,  1.6132e-03,  2.9669e-03, -1.5606e-03,\n",
            "          2.1566e-03, -5.9970e-04,  1.0974e-03,  2.8536e-03, -1.5761e-03,\n",
            "         -1.1973e-03,  1.4157e-03,  1.0819e-03, -1.6395e-04,  1.4259e-03,\n",
            "         -1.5993e-03,  4.9925e-04,  2.4320e-03,  2.8718e-03,  7.4142e-04],\n",
            "        [-1.3084e-02, -1.9413e-02, -3.0946e-02, -2.5855e-02, -2.5361e-02,\n",
            "         -1.3386e-02, -1.6360e-02, -1.5787e-02, -2.4764e-02, -2.0017e-02,\n",
            "         -1.5216e-02, -1.7701e-02, -1.4559e-02, -2.9177e-02, -1.7573e-02,\n",
            "         -1.8530e-02, -1.0069e-02, -9.5260e-03, -1.8987e-02, -1.7839e-02],\n",
            "        [ 4.8107e-04,  7.2480e-04,  9.8633e-05,  8.6471e-04,  1.9964e-03,\n",
            "          1.6202e-03,  1.1736e-03,  2.0290e-03,  3.3147e-04,  3.0171e-03,\n",
            "          1.0456e-03,  1.1400e-03,  5.0297e-04,  3.3159e-04,  1.9707e-03,\n",
            "          3.4884e-04,  8.4107e-04,  2.6777e-03,  8.6282e-04,  5.8412e-04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 在Pytorch中实现动量法\n",
        "# 恢复小步长\n",
        "lr = 0.1\n",
        "gamma = 0.9\n",
        "\n",
        "dw = net.linear1.weight.grad\n",
        "w = net.linear1.weight.data\n",
        "print(dw)\n",
        "print(w)\n",
        "# v要能够与dw相减，因此必须保持与w相同的结构\n",
        "v = torch.zeros(dw.shape[0], dw.shape[1])\n",
        "v = gamma * v - lr * dw\n",
        "w = w - v\n",
        "print(w)"
      ],
      "metadata": {
        "id": "XFcJyxWFGl4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b7ed27-6a88-4877-a8f6-db2c3fee2d45"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3.3727e-04,  8.3354e-05,  4.0867e-04,  4.3058e-05,  1.4551e-04,\n",
            "          6.5092e-05,  3.7088e-04,  2.8794e-04,  1.0495e-04,  4.7446e-05,\n",
            "          8.8153e-05,  1.6899e-04,  1.0251e-04,  3.6197e-04,  1.2129e-04,\n",
            "          7.2405e-05,  1.4479e-04,  4.9114e-06,  1.0770e-04,  9.5156e-05],\n",
            "        [ 8.2042e-03,  2.1974e-02,  2.1073e-02,  1.3896e-02,  2.2161e-02,\n",
            "          1.5936e-02,  1.6537e-02,  2.0259e-02,  1.9655e-02,  1.4728e-02,\n",
            "          1.9212e-02,  2.0086e-02,  1.8295e-02,  8.4132e-03,  1.8036e-02,\n",
            "          1.9979e-02,  2.0966e-02,  2.4730e-02,  9.3876e-03,  1.7475e-02],\n",
            "        [ 9.1603e-03,  2.4275e-02,  2.3446e-02,  2.0096e-02,  2.5360e-02,\n",
            "          1.7406e-02,  3.2555e-02,  2.2461e-02,  3.6793e-03,  2.7445e-02,\n",
            "          2.1181e-02,  2.7724e-02,  1.7115e-02,  1.6943e-02,  1.7249e-02,\n",
            "          3.3173e-02,  1.5115e-02,  3.0874e-02,  1.8391e-02,  2.4201e-02],\n",
            "        [-2.8595e-04,  1.2968e-03,  1.3652e-03, -5.6692e-05, -1.7480e-03,\n",
            "         -2.6459e-03,  3.7307e-04, -2.7976e-03,  1.7848e-03, -9.9289e-04,\n",
            "         -3.3944e-04,  2.2783e-04,  1.2076e-03, -3.2906e-04,  5.4641e-04,\n",
            "         -2.8959e-03, -2.7890e-03, -3.0774e-03, -3.8981e-03, -6.0863e-03],\n",
            "        [ 1.5692e-03,  1.3161e-03, -9.0900e-04, -1.0158e-03, -4.9426e-03,\n",
            "          1.3061e-03, -6.8428e-03, -1.0955e-02,  4.2490e-03, -9.7841e-03,\n",
            "         -3.5231e-03, -6.9716e-03,  1.0742e-02,  2.9732e-03, -2.2283e-03,\n",
            "         -4.3101e-03, -1.2823e-03, -6.0040e-03, -1.5857e-03, -3.2208e-03],\n",
            "        [-2.3456e-03,  3.0270e-04, -9.7571e-04, -1.7812e-03, -1.9554e-03,\n",
            "          4.7728e-04, -7.5906e-04, -9.3554e-04, -8.6828e-04, -4.9501e-04,\n",
            "         -3.2291e-03, -2.6119e-03, -9.4872e-04, -1.3638e-03, -1.7115e-03,\n",
            "         -9.1220e-04, -1.0843e-03, -8.5492e-04,  1.5598e-04, -2.5193e-03],\n",
            "        [-1.8459e-02, -2.0009e-02, -1.3430e-02, -1.5675e-02, -1.3660e-02,\n",
            "         -1.4804e-02, -8.0083e-03, -2.0027e-02, -2.9173e-02,  7.5748e-03,\n",
            "         -1.8572e-02, -5.4350e-03, -3.2866e-02, -9.2504e-03, -1.8047e-02,\n",
            "         -9.1732e-03, -1.6036e-02, -1.4584e-02, -8.9602e-03,  1.7230e-03],\n",
            "        [ 9.5595e-04, -2.0620e-02, -2.6421e-02, -1.9139e-02, -2.5206e-02,\n",
            "         -9.0114e-03, -2.5945e-02, -1.8858e-02, -3.5860e-03, -3.2187e-02,\n",
            "         -1.8400e-02, -1.8522e-02, -1.1765e-02, -1.5216e-02, -8.4282e-03,\n",
            "         -3.0337e-02, -1.1364e-02, -2.9159e-02, -5.1049e-03, -2.6377e-02],\n",
            "        [ 3.7390e-03, -1.3553e-03, -2.2382e-03,  2.2693e-03, -1.4464e-03,\n",
            "         -2.4332e-03, -3.7881e-03,  7.3999e-04,  1.2527e-02, -1.9007e-03,\n",
            "          7.8561e-03, -9.5000e-03,  9.1147e-03, -2.2882e-03,  5.5781e-03,\n",
            "         -5.0263e-03,  4.8214e-03,  2.0531e-03,  4.1112e-04, -2.4565e-03],\n",
            "        [ 2.4338e-03,  2.9046e-03, -1.0326e-02, -4.4877e-03, -8.1686e-05,\n",
            "         -3.0232e-03,  3.2874e-03, -7.5255e-03, -1.0000e-02,  3.9967e-03,\n",
            "          6.3736e-03, -2.3521e-03, -3.5956e-03, -4.8027e-03, -2.7523e-03,\n",
            "          1.6497e-03, -1.3330e-03,  3.1406e-03,  4.9480e-03, -1.5097e-03],\n",
            "        [-7.3584e-04,  9.5657e-04,  1.6132e-03,  2.9669e-03, -1.5606e-03,\n",
            "          2.1566e-03, -5.9970e-04,  1.0974e-03,  2.8536e-03, -1.5761e-03,\n",
            "         -1.1973e-03,  1.4157e-03,  1.0819e-03, -1.6395e-04,  1.4259e-03,\n",
            "         -1.5993e-03,  4.9925e-04,  2.4320e-03,  2.8718e-03,  7.4142e-04],\n",
            "        [-1.3084e-02, -1.9413e-02, -3.0946e-02, -2.5855e-02, -2.5361e-02,\n",
            "         -1.3386e-02, -1.6360e-02, -1.5787e-02, -2.4764e-02, -2.0017e-02,\n",
            "         -1.5216e-02, -1.7701e-02, -1.4559e-02, -2.9177e-02, -1.7573e-02,\n",
            "         -1.8530e-02, -1.0069e-02, -9.5260e-03, -1.8987e-02, -1.7839e-02],\n",
            "        [ 4.8107e-04,  7.2480e-04,  9.8633e-05,  8.6471e-04,  1.9964e-03,\n",
            "          1.6202e-03,  1.1736e-03,  2.0290e-03,  3.3147e-04,  3.0171e-03,\n",
            "          1.0456e-03,  1.1400e-03,  5.0297e-04,  3.3159e-04,  1.9707e-03,\n",
            "          3.4884e-04,  8.4107e-04,  2.6777e-03,  8.6282e-04,  5.8412e-04]])\n",
            "tensor([[ 1.3656e-01, -1.3459e-01,  2.1281e-01, -1.7763e-01, -6.8218e-02,\n",
            "         -1.5410e-01,  1.7245e-01,  8.3885e-02, -1.1153e-01, -1.7294e-01,\n",
            "         -1.2947e-01, -4.3138e-02, -1.1413e-01,  1.6295e-01, -9.4082e-02,\n",
            "         -1.4629e-01, -6.8982e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
            "        [ 4.8127e-02,  1.8186e-01,  2.4149e-02, -1.3032e-01,  9.2056e-02,\n",
            "         -9.5202e-02, -1.0584e-01, -4.2852e-02, -1.1669e-01,  2.4581e-02,\n",
            "          1.8152e-01,  3.0500e-02,  1.3506e-01, -1.9425e-01, -1.7591e-01,\n",
            "         -2.9751e-02,  2.0485e-04,  1.3957e-01, -1.9666e-01,  9.3293e-02],\n",
            "        [-1.9192e-01,  3.6070e-02,  1.4778e-01,  3.0845e-02,  7.1393e-02,\n",
            "          1.4217e-01,  2.2122e-01, -1.4032e-01,  7.3255e-02,  1.8409e-01,\n",
            "          1.2716e-01, -2.0253e-01, -1.5509e-01, -2.1899e-01,  9.8980e-02,\n",
            "          2.2123e-01, -2.1659e-01,  1.7880e-01, -2.0922e-01, -2.7275e-02],\n",
            "        [ 1.8144e-01, -3.5166e-02,  2.4801e-02,  1.6299e-01, -1.8755e-01,\n",
            "          5.6587e-02, -1.0911e-01,  2.0523e-01, -1.9378e-01,  1.6899e-02,\n",
            "          1.3966e-01, -1.3137e-01, -1.3201e-01,  7.6554e-02, -1.7558e-01,\n",
            "          1.3096e-01,  2.7182e-02, -2.2010e-01,  7.6883e-02, -1.8731e-01],\n",
            "        [ 2.7419e-02,  1.3699e-01, -3.8687e-02,  8.3463e-02, -1.5634e-02,\n",
            "         -1.6781e-01, -2.1426e-01,  1.8463e-01,  8.3891e-02,  5.9950e-02,\n",
            "         -2.0538e-01, -2.7832e-02,  4.7442e-02, -1.9782e-01, -1.7842e-01,\n",
            "          1.1362e-01,  1.4100e-01, -1.3794e-01,  1.1704e-01, -3.4108e-02],\n",
            "        [ 3.8388e-02, -1.7268e-01, -1.0235e-01, -1.2634e-01, -1.1883e-01,\n",
            "         -1.3463e-01, -1.7610e-01,  3.6543e-02, -1.7834e-01, -1.6471e-01,\n",
            "          2.0834e-01,  1.8400e-01, -8.8723e-02, -7.5378e-02,  1.7877e-01,\n",
            "         -5.7259e-02, -2.4522e-02, -1.1822e-02, -1.8196e-01,  1.9812e-01],\n",
            "        [-2.2011e-02,  2.1847e-01,  1.8410e-01,  9.7177e-02, -5.0634e-03,\n",
            "         -2.4731e-03,  5.1408e-03, -2.1733e-01, -5.3375e-02, -1.0346e-01,\n",
            "         -1.3303e-02,  2.7354e-02, -1.7523e-01,  1.6994e-01,  1.8259e-01,\n",
            "          1.3907e-01,  1.0041e-01,  3.5377e-02, -1.6114e-01,  9.0056e-02],\n",
            "        [ 7.9232e-02,  2.1614e-01, -2.1087e-01,  1.9407e-01,  1.7559e-01,\n",
            "          4.1470e-02,  7.4482e-02,  2.6737e-02, -1.7872e-02,  4.5040e-02,\n",
            "          1.2947e-01,  2.5483e-02, -2.0320e-02, -7.3942e-03, -1.7221e-01,\n",
            "         -1.0705e-01,  1.8203e-01,  1.3179e-02,  2.3468e-02, -1.9567e-01],\n",
            "        [ 1.6338e-01,  8.0209e-03, -2.9885e-02, -2.1884e-01,  1.3471e-01,\n",
            "         -2.8901e-02, -1.8757e-01,  8.9256e-03,  2.0940e-01,  9.0927e-02,\n",
            "         -8.2969e-02, -9.0893e-03,  1.0047e-01, -1.6897e-02, -1.3736e-01,\n",
            "          1.6801e-01, -1.9342e-01, -3.4822e-02,  1.0057e-01,  2.2273e-02],\n",
            "        [ 1.4611e-01,  1.4414e-01, -2.3093e-02,  8.1946e-02,  5.9792e-03,\n",
            "          6.7672e-02,  1.5254e-01,  1.6742e-01, -1.6896e-01,  1.1571e-01,\n",
            "         -1.8538e-01,  2.3316e-02, -1.6147e-01,  1.0230e-01, -1.7314e-01,\n",
            "         -1.8906e-01, -2.0286e-01, -2.1210e-02, -2.1799e-02, -3.7921e-02],\n",
            "        [ 1.9375e-01,  5.3921e-02, -1.4900e-01,  1.6709e-01, -1.6652e-01,\n",
            "          6.2363e-02, -4.1574e-02, -2.0565e-01, -1.3649e-01, -2.0600e-01,\n",
            "         -1.9032e-01, -8.8942e-02, -7.8061e-02,  1.6323e-01, -1.3174e-01,\n",
            "          5.8638e-02,  2.1117e-01,  1.6707e-01, -5.9492e-02, -2.0973e-01],\n",
            "        [-2.5644e-02, -1.0818e-02, -3.3051e-02,  3.7071e-02, -1.0809e-01,\n",
            "          2.0642e-01,  1.2396e-01, -2.1523e-01,  1.2172e-01, -1.4323e-01,\n",
            "          1.1334e-01,  4.6931e-02,  8.4553e-02,  2.0530e-01, -1.1833e-01,\n",
            "          1.9287e-01, -2.8398e-02,  7.1443e-03, -2.1055e-01,  1.0805e-01],\n",
            "        [-1.2258e-01, -6.8325e-02, -2.1929e-01, -1.4939e-01,  1.9226e-01,\n",
            "         -6.2922e-02, -7.6377e-02,  2.1955e-01, -4.5838e-02,  9.8011e-03,\n",
            "         -2.9401e-03, -9.5241e-02, -7.9775e-02, -1.8708e-01,  1.7828e-01,\n",
            "         -1.7552e-01, -1.0328e-01, -1.9697e-02, -1.7449e-01,  2.0408e-02]])\n",
            "tensor([[ 0.1366, -0.1346,  0.2128, -0.1776, -0.0682, -0.1541,  0.1725,  0.0839,\n",
            "         -0.1115, -0.1729, -0.1295, -0.0431, -0.1141,  0.1630, -0.0941, -0.1463,\n",
            "         -0.0690, -0.2184, -0.1086, -0.1220],\n",
            "        [ 0.0489,  0.1841,  0.0263, -0.1289,  0.0943, -0.0936, -0.1042, -0.0408,\n",
            "         -0.1147,  0.0261,  0.1834,  0.0325,  0.1369, -0.1934, -0.1741, -0.0278,\n",
            "          0.0023,  0.1420, -0.1957,  0.0950],\n",
            "        [-0.1910,  0.0385,  0.1501,  0.0329,  0.0739,  0.1439,  0.2245, -0.1381,\n",
            "          0.0736,  0.1868,  0.1293, -0.1998, -0.1534, -0.2173,  0.1007,  0.2246,\n",
            "         -0.2151,  0.1819, -0.2074, -0.0249],\n",
            "        [ 0.1814, -0.0350,  0.0249,  0.1630, -0.1877,  0.0563, -0.1091,  0.2050,\n",
            "         -0.1936,  0.0168,  0.1396, -0.1313, -0.1319,  0.0765, -0.1755,  0.1307,\n",
            "          0.0269, -0.2204,  0.0765, -0.1879],\n",
            "        [ 0.0276,  0.1371, -0.0388,  0.0834, -0.0161, -0.1677, -0.2149,  0.1835,\n",
            "          0.0843,  0.0590, -0.2057, -0.0285,  0.0485, -0.1975, -0.1786,  0.1132,\n",
            "          0.1409, -0.1385,  0.1169, -0.0344],\n",
            "        [ 0.0382, -0.1727, -0.1025, -0.1265, -0.1190, -0.1346, -0.1762,  0.0364,\n",
            "         -0.1784, -0.1648,  0.2080,  0.1837, -0.0888, -0.0755,  0.1786, -0.0574,\n",
            "         -0.0246, -0.0119, -0.1819,  0.1979],\n",
            "        [-0.0239,  0.2165,  0.1828,  0.0956, -0.0064, -0.0040,  0.0043, -0.2193,\n",
            "         -0.0563, -0.1027, -0.0152,  0.0268, -0.1785,  0.1690,  0.1808,  0.1382,\n",
            "          0.0988,  0.0339, -0.1620,  0.0902],\n",
            "        [ 0.0793,  0.2141, -0.2135,  0.1922,  0.1731,  0.0406,  0.0719,  0.0249,\n",
            "         -0.0182,  0.0418,  0.1276,  0.0236, -0.0215, -0.0089, -0.1731, -0.1101,\n",
            "          0.1809,  0.0103,  0.0230, -0.1983],\n",
            "        [ 0.1638,  0.0079, -0.0301, -0.2186,  0.1346, -0.0291, -0.1879,  0.0090,\n",
            "          0.2107,  0.0907, -0.0822, -0.0100,  0.1014, -0.0171, -0.1368,  0.1675,\n",
            "         -0.1929, -0.0346,  0.1006,  0.0220],\n",
            "        [ 0.1464,  0.1444, -0.0241,  0.0815,  0.0060,  0.0674,  0.1529,  0.1667,\n",
            "         -0.1700,  0.1161, -0.1847,  0.0231, -0.1618,  0.1018, -0.1734, -0.1889,\n",
            "         -0.2030, -0.0209, -0.0213, -0.0381],\n",
            "        [ 0.1937,  0.0540, -0.1488,  0.1674, -0.1667,  0.0626, -0.0416, -0.2055,\n",
            "         -0.1362, -0.2062, -0.1904, -0.0888, -0.0780,  0.1632, -0.1316,  0.0585,\n",
            "          0.2112,  0.1673, -0.0592, -0.2097],\n",
            "        [-0.0270, -0.0128, -0.0361,  0.0345, -0.1106,  0.2051,  0.1223, -0.2168,\n",
            "          0.1192, -0.1452,  0.1118,  0.0452,  0.0831,  0.2024, -0.1201,  0.1910,\n",
            "         -0.0294,  0.0062, -0.2124,  0.1063],\n",
            "        [-0.1225, -0.0683, -0.2193, -0.1493,  0.1925, -0.0628, -0.0763,  0.2198,\n",
            "         -0.0458,  0.0101, -0.0028, -0.0951, -0.0797, -0.1871,  0.1785, -0.1755,\n",
            "         -0.1032, -0.0194, -0.1744,  0.0205]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "# torch.optim实现带动量的梯度下降\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# 确定数据、确定优先需要设置的值\n",
        "lr = 0.1\n",
        "gamma = 0.9\n",
        "\n",
        "torch.manual_seed(420)\n",
        "X = torch.rand((500, 20), dtype=torch.float32) * 100\n",
        "y = torch.randint(low=0, high=3, size=(500, 1), dtype=torch.float32)\n",
        "input_ = X.shape[1] # 特征的数目\n",
        "output_ = len(y.unique()) # 分类的数目\n",
        "\n",
        "# 定义神经网络的架构\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear1 = nn.Linear(in_features, 13, bias=True)\n",
        "    self.linear2 = nn.Linear(13, 8, bias=True)\n",
        "    self.output = nn.Linear(8, out_features, bias=True)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    z1 = self.linear1(X)\n",
        "    sigma1 = torch.relu(z1)\n",
        "    z2 = self.linear2(sigma1)\n",
        "    sigma2 = torch.sigmoid(z2)\n",
        "    z3 = self.output(sigma2)\n",
        "    #sigma3 = F.softmax(z3)\n",
        "    return z3\n",
        "  \n",
        "# 实例化神经网络, 调用优化算法需要的参数\n",
        "torch.manual_seed(420)\n",
        "net = Model(in_features=input_, out_features=output_)\n",
        "net.parameters() # 一次性导出神经网络架构下全部的权重和截距\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义优化算法\n",
        "opt = optim.SGD(net.parameters(), # 要优化的参数是哪些\n",
        "         lr = lr, # 学习率\n",
        "         momentum = gamma) # 动量参数"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJde3xANNmsx",
        "outputId": "228c5ef4-19cd-4846-a211-86ada47be2e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Module.parameters at 0x7fecac82de50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 接下来开始进行一轮梯度下降\n",
        "zhat = net.forward(X) #前向传播\n",
        "loss = criterion(zhat, y.reshape(500).long()) # 损失函数值\n",
        "loss.backward() # 反向传播\n",
        "opt.step() # 更新权重w,从这一瞬间开始，坐标点就发生了变化，所有的梯度必须重新计算\n",
        "opt.zero_grad() # 清除原来储存好的，基于上一个坐标点计算的梯度，为下一次计算梯度腾出空间\n",
        "\n",
        "print(loss)\n",
        "print(net.linear1.weight.data[0][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb10vjT_dj90",
        "outputId": "e1ad4acf-32e2-493c-8a61-c3155c74b683"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0851, grad_fn=<NllLossBackward0>)\n",
            "tensor([ 0.1380, -0.1342,  0.2146, -0.1774, -0.0676, -0.1538,  0.1740,  0.0851,\n",
            "        -0.1111, -0.1727])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorDataset与DataLoader\n",
        "# TensorDataset -将特征与标签合并到同一个对象中\n",
        "# LoadData -帮助我们进行小批量的分割\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "a = torch.randn(500, 2, 3)\n",
        "b = torch.randn(500, 3, 4, 5)\n",
        "c = torch.randn(500, 1)\n",
        "\n",
        "# 被合并的对象第一维度上的值相等\n",
        "for i in TensorDataset(b, c):\n",
        "  print(i)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lK7vzaffOpm",
        "outputId": "d49d0f12-de24-4f36-b9b3-fceff0ca87ff"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[ 1.4324, -1.5099,  0.9286, -0.2416,  0.5485],\n",
            "         [ 2.4199, -0.0434, -0.0223,  0.4258, -2.3547],\n",
            "         [ 0.5817, -0.1884, -1.4250, -0.5167, -0.6050],\n",
            "         [-0.0143,  0.1180,  0.3792,  0.6414,  0.1110]],\n",
            "\n",
            "        [[ 0.1669,  0.2931,  3.3509,  1.6537,  1.2335],\n",
            "         [-0.8471, -0.1266, -0.1298,  0.1220, -0.4691],\n",
            "         [-0.0292,  0.5957,  0.4642, -0.6832,  1.3422],\n",
            "         [-0.3683,  1.6137,  0.0393,  2.1853,  1.5552]],\n",
            "\n",
            "        [[ 0.9770,  0.2914,  1.3271, -0.2651, -0.5037],\n",
            "         [ 2.1154, -0.6312,  0.1289, -1.2272, -0.0769],\n",
            "         [ 0.3284, -0.4702, -0.1327, -1.3445,  1.3452],\n",
            "         [-0.3232,  0.7399,  0.2545,  0.0505,  0.9385]]]), tensor([-0.7568]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用划分小批量的功能DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "data = TensorDataset(b, c)\n",
        "for i in DataLoader(data):\n",
        "  print(i)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CLMzn8MsH0f",
        "outputId": "7811e218-3bd4-4bc4-8974-a33187b988f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[[[ 1.4324, -1.5099,  0.9286, -0.2416,  0.5485],\n",
            "          [ 2.4199, -0.0434, -0.0223,  0.4258, -2.3547],\n",
            "          [ 0.5817, -0.1884, -1.4250, -0.5167, -0.6050],\n",
            "          [-0.0143,  0.1180,  0.3792,  0.6414,  0.1110]],\n",
            "\n",
            "         [[ 0.1669,  0.2931,  3.3509,  1.6537,  1.2335],\n",
            "          [-0.8471, -0.1266, -0.1298,  0.1220, -0.4691],\n",
            "          [-0.0292,  0.5957,  0.4642, -0.6832,  1.3422],\n",
            "          [-0.3683,  1.6137,  0.0393,  2.1853,  1.5552]],\n",
            "\n",
            "         [[ 0.9770,  0.2914,  1.3271, -0.2651, -0.5037],\n",
            "          [ 2.1154, -0.6312,  0.1289, -1.2272, -0.0769],\n",
            "          [ 0.3284, -0.4702, -0.1327, -1.3445,  1.3452],\n",
            "          [-0.3232,  0.7399,  0.2545,  0.0505,  0.9385]]]]), tensor([[-0.7568]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoad()的参数\n",
        "bs = 120\n",
        "dataset = DataLoader(data,\n",
        "           batch_size=bs,\n",
        "           shuffle=True,\n",
        "           drop_last=True)\n",
        "\n",
        "for i in dataset:\n",
        "  print(i[0].shape)\n",
        "\n",
        "print(len(dataset)) # 一共有多少个batch\n",
        "print(len(dataset.dataset)) # 展示里面全部的数据\n",
        "print(dataset.dataset[0]) # 单个样本\n",
        "print(dataset.dataset[0][0]) # 单个样本的特征\n",
        "print(dataset.dataset[0][1]) # 单个样本的标签\n",
        "print(dataset.batch_size) # 查看现有的batch_size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWsXD0SKvuDR",
        "outputId": "ecea48b4-0685-4d2d-aa34-410fac49494d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([120, 3, 4, 5])\n",
            "torch.Size([120, 3, 4, 5])\n",
            "torch.Size([120, 3, 4, 5])\n",
            "torch.Size([120, 3, 4, 5])\n",
            "4\n",
            "500\n",
            "(tensor([[[ 1.4324, -1.5099,  0.9286, -0.2416,  0.5485],\n",
            "         [ 2.4199, -0.0434, -0.0223,  0.4258, -2.3547],\n",
            "         [ 0.5817, -0.1884, -1.4250, -0.5167, -0.6050],\n",
            "         [-0.0143,  0.1180,  0.3792,  0.6414,  0.1110]],\n",
            "\n",
            "        [[ 0.1669,  0.2931,  3.3509,  1.6537,  1.2335],\n",
            "         [-0.8471, -0.1266, -0.1298,  0.1220, -0.4691],\n",
            "         [-0.0292,  0.5957,  0.4642, -0.6832,  1.3422],\n",
            "         [-0.3683,  1.6137,  0.0393,  2.1853,  1.5552]],\n",
            "\n",
            "        [[ 0.9770,  0.2914,  1.3271, -0.2651, -0.5037],\n",
            "         [ 2.1154, -0.6312,  0.1289, -1.2272, -0.0769],\n",
            "         [ 0.3284, -0.4702, -0.1327, -1.3445,  1.3452],\n",
            "         [-0.3232,  0.7399,  0.2545,  0.0505,  0.9385]]]), tensor([-0.7568]))\n",
            "tensor([[[ 1.4324, -1.5099,  0.9286, -0.2416,  0.5485],\n",
            "         [ 2.4199, -0.0434, -0.0223,  0.4258, -2.3547],\n",
            "         [ 0.5817, -0.1884, -1.4250, -0.5167, -0.6050],\n",
            "         [-0.0143,  0.1180,  0.3792,  0.6414,  0.1110]],\n",
            "\n",
            "        [[ 0.1669,  0.2931,  3.3509,  1.6537,  1.2335],\n",
            "         [-0.8471, -0.1266, -0.1298,  0.1220, -0.4691],\n",
            "         [-0.0292,  0.5957,  0.4642, -0.6832,  1.3422],\n",
            "         [-0.3683,  1.6137,  0.0393,  2.1853,  1.5552]],\n",
            "\n",
            "        [[ 0.9770,  0.2914,  1.3271, -0.2651, -0.5037],\n",
            "         [ 2.1154, -0.6312,  0.1289, -1.2272, -0.0769],\n",
            "         [ 0.3284, -0.4702, -0.1327, -1.3445,  1.3452],\n",
            "         [-0.3232,  0.7399,  0.2545,  0.0505,  0.9385]]])\n",
            "tensor([-0.7568])\n",
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 对于小批量随机梯度下降而言，我们一般这样使用TensorDataset与DataLoader:\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(420)\n",
        "X = torch.rand((50000, 20), dtype=torch.float32) * 100 \n",
        "y = torch.randint(low=0, high=3, size=(50000, 1), dtype=torch.float32)\n",
        "\n",
        "epochs = 4 # 请让神经网络学习4次数据\n",
        "bs = 4000\n",
        "\n",
        "data = TensorDataset(X, y)\n",
        "batchdata = DataLoader(data,\n",
        "            batch_size=bs,\n",
        "            shuffle=True)\n",
        "\n",
        "print(len(batchdata)) # 查看具体被分了多少个batch 13\n",
        "\n",
        "# 可以使用.datasets查看数据集相关的属性\n",
        "print(len(batchdata.dataset)) # 总共有多少数据 50000\n",
        "print(batchdata.dataset[0]) # 查看其中一个样本\n",
        "print(batchdata.dataset[0][0]) # 一个样本的特征张量\n",
        "print(batchdata.dataset[0][0]) # 一个样本的标签\n",
        "print(batchdata.batch_size) # 查看现在的batch_size是多少 4000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EjTGoZe3wDr",
        "outputId": "c3942fe3-c9e8-40f1-bbec-98c1f14adf19"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "50000\n",
            "(tensor([80.5354, 19.9040, 97.5853, 10.2817, 34.7460, 15.5433, 88.5615, 68.7572,\n",
            "        25.0620, 11.3297, 21.0499, 40.3541, 24.4790, 86.4358, 28.9626, 17.2895,\n",
            "        34.5751,  1.1728, 25.7179, 22.7224]), tensor([2.]))\n",
            "tensor([80.5354, 19.9040, 97.5853, 10.2817, 34.7460, 15.5433, 88.5615, 68.7572,\n",
            "        25.0620, 11.3297, 21.0499, 40.3541, 24.4790, 86.4358, 28.9626, 17.2895,\n",
            "        34.5751,  1.1728, 25.7179, 22.7224])\n",
            "tensor([80.5354, 19.9040, 97.5853, 10.2817, 34.7460, 15.5433, 88.5615, 68.7572,\n",
            "        25.0620, 11.3297, 21.0499, 40.3541, 24.4790, 86.4358, 28.9626, 17.2895,\n",
            "        34.5751,  1.1728, 25.7179, 22.7224])\n",
            "4000\n"
          ]
        }
      ]
    }
  ]
}