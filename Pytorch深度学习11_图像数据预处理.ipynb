{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch深度学习11-图像数据预处理.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMs9sk55idX1kaz26279b0y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GzpTez0514/-/blob/main/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A011_%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKl4aNXsyKdZ"
      },
      "outputs": [],
      "source": [
        "# 定义Dataset的子类\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import torch, torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random # 为了plotsamples而导入\n",
        "\n",
        "# 包含了所有图像的目录，没有具体到某一张图像\n",
        "imgpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "# 标签文件的目录\n",
        "csvpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "identity = pd.read_csv(csvpath, sep=' ', header=None)\n",
        "print(identity.head())\n",
        "\n",
        "imgdic = os.path.join(imgpath, identity.iloc[0, 0])\n",
        "print(imgdic)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将读取的标签和图像合并\n",
        "idx = 0 # 自定义\n",
        "imgpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "csvpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "imgdic = os.path.join(imgpath, identity.iloc[index, 0])\n",
        "iamge = torch.tensor(io.imread(imgdic))\n",
        "sample = (image, int(identity.iloc[index, 0]))\n",
        "print(image.shape)\n",
        "print(sample)\n",
        "# 成功读取一张图片，并将它和标签打包成一个元组"
      ],
      "metadata": {
        "id": "3GCRfDKa790Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 更换文件拓展名\n",
        "# identity是个体识别的标签\n",
        "identity2 = identity.copy()\n",
        "identity2['2'] = [x[:-3] + 'png' for x in identity2.iloc[:, 0]]\n",
        "print(identity2.head())\n",
        "imgpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "csvpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "imgdic = os.path.join(imgpath, identity2.iloc[idx, 2])\n",
        "image = torch.tensor(io.imread(imgdic))\n",
        "sample = (image, int(identity.iloc[idx, 1]))"
      ],
      "metadata": {
        "id": "6ByXEgYcJIvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 包装成类\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import torch, torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  '''\n",
        "  自定义数据集，用于读取celebA数据集中的个体识别数据的标签和图像\n",
        "  图像的格式为jpg\n",
        "  '''\n",
        "  def __init__(self, csv_file, root_dir, transform=None):\n",
        "    '''\n",
        "    参数说明：\n",
        "      csv_file:标签的具体位置\n",
        "      root_dir：所有图片所在的根目录\n",
        "      transform：选填，需要对样本进行预处理\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.identity = pd.read_csv(csv_file, sep=' ', header=None)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    # 展示数据总共有多少个样本\n",
        "    return len(self.identity)\n",
        "\n",
        "  def __info__(self):\n",
        "    print('CustomData')\n",
        "    print(f'\\t Number of samples: {len(self.identity)}')\n",
        "    print(f'\\t Number of classes: {len(np.unique(self.identity.iloc[:, 1]))}')\n",
        "    print(f'\\t root_dir: {self.root_dir}')\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # 保证idx不是一个tensor\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    # 图像目录\n",
        "    imgdic = os.path.join(self.root, self.identity.iloc[idex, 0])\n",
        "    # 提取出的，索引为idx的图像的像素值矩阵\n",
        "    image = io.imread(imgdic)\n",
        "    label = self.identity.iloc[idex, 1]\n",
        "\n",
        "    if self.transform != None:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    sample = (image, label)\n",
        "    return sample\n",
        "\n",
        "img_path = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "csv_path = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "\n",
        "data = CustomDataset(root_dir=img_path, \n",
        "           csv_file=csv_path, \n",
        "           transform=transforms.Totensor())\n",
        "\n",
        "print(data.__info__())\n",
        "print(__len__())\n",
        "\n",
        "for x,y in data:\n",
        "  print(x.shape, y)\n",
        "  break\n",
        "\n",
        "# getitem的存在令子类生成的数据能够被索引调用和查看\n",
        "data[998]\n",
        "\n",
        "# 让每个数据集随机显示5张图片\n",
        "plotsample(data)\n",
        "\n",
        "# 用来分割训练集和测试集的工具\n",
        "from torch.utils.data import random_split\n",
        "print(data.__len__())\n",
        "\n",
        "train, test = random_split(data, [700, 300], generator=torch.Generator().manual_seed(42))\n",
        "print(train.__len__()) # 分割数据集由Dataset变成了Subset, 继承自Dataset类的方法会全保留，而自己设置的方法则会失效\n",
        "print(train.__info__())\n",
        "print(test.__len__()"
      ],
      "metadata": {
        "id": "mjKoA1e4fqYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 读取标签属性，并放置到类CustomDataset_attr中\n",
        "class CustomDataset_attr(Dataset):\n",
        "  '''\n",
        "  自定义数据集，用于读取celeBA数据集中的属性识别数据的标签和图像\n",
        "  图像格式为jpg\n",
        "  '''\n",
        "  def __init__(self, csv_file, root_dir, labelname, transform=None):\n",
        "    '''\n",
        "    参数说明：\n",
        "      csv_file:标签的具体地址\n",
        "      root_dir:所有图片所在的根目录\n",
        "      transform:选填，需要对样本进行的预处理\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.attr_ = pd.read_csv(csv_path, header=None)\n",
        "    self.root_dir = root_dir\n",
        "    self.labelname = labelname\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    # 展示数据中总共有多少个样本\n",
        "    return len(self.attr_)\n",
        "\n",
        "  def __info__(self):\n",
        "    print('CustomData')\n",
        "    print(f'\\t Number of samples: {len(self.sttr_) - 1}')\n",
        "    print(f'\\t root_dir: {self.root_dir}')\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # 保证idx不是一个tensor\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    \n",
        "    self.attr_ = pd.DataFrame(self.attr_.iloc[1:, 0].str.split().tolist(),\n",
        "                  columns=self.attr_.iloc[0, 0].split())\n",
        "    \n",
        "    imgdic = os.path.join(self.root_dir, self.attr_.iloc[idx, 0]) # 图像目录\n",
        "    image = io.imread(imgdic) # 提取出的，索引为idx的图像的像素值矩阵\n",
        "    label = int(self.attr_.loc[idx, self.labelname])\n",
        "\n",
        "    if self.transform != None:\n",
        "      image = self.transform(image)\n",
        "    \n",
        "    sample = (image, label)\n",
        "    return sample\n",
        "\n",
        "imgpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "csv_path = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "labelname = 'Attractive'\n",
        "\n",
        "data = CustomDataset_attr(csv_path, img_path, labelname)\n",
        "print(data)\n",
        "print(data.__info__())\n",
        "print(data[500])"
      ],
      "metadata": {
        "id": "dVKeZPM6tFIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 从二维表到四维tensor\n",
        "# csv\n",
        "import pandas as pd\n",
        "data = pd.read_csv(r'........')\n",
        "\n",
        "# txt\n",
        "data = pd.read_csv(r'........', sep=' ')\n",
        "\n",
        "# 导入数据之后，将二维表格整理成更高维的数据，就可以放入卷积网络进行训练\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.random.randint(0, 255, (10, 10000)) # 假设现在是10个样本，每个样本10000个特征\n",
        "data.reshape(10, 1, 100, 100) # 可以直接使用reshape的方式将数据调整为4维\n",
        "data = torch.tensor(data) # 再放入tensor中转换格式\n",
        "plt.imshow(data.view(-1, 100, 100, 1)[0])\n",
        "print(data)"
      ],
      "metadata": {
        "id": "8kcLrv-r9S-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 多项式升维\n",
        "from sklearn.preprocessing import PolynomialFeatures as PF\n",
        "import numpy as np\n",
        "\n",
        "# 如果数据是一维的\n",
        "x = np.arange(1, 4).reshape(-1, 1)\n",
        "print(x)\n",
        "\n",
        "# 二次多项式，参数degree控制多项式的次方\n",
        "poly = PF(degree=2)\n",
        "\n",
        "# 接口transform直接调用\n",
        "x_ = poly.fit_transform(x)\n",
        "print(x_)\n",
        "\n",
        "# 三次多项式\n",
        "PF(degree=3).fit_transform(x)\n"
      ],
      "metadata": {
        "id": "eeOKf6Qp8-LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 从mat/pt/Imdb到四维tensor\n",
        "# FashionMNIST数据集就是pt格式的数据,可以直接使用torch.load进行读取\n",
        "import torch\n",
        "x, y = torch.load(r'-------------')\n",
        "print(x.shape)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "YAqMmUAZF1L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 图片数据的预处理与数据增强\n",
        "# 1、数据预处理\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "\n",
        "transform = transform.Compose([transforms.Resize(256), transforms.CenterCrop(224)])\n",
        "# 等价于\n",
        "transform = nn.Sequential(transforms.Resize(256), transforms.CenterCrop(224))\n",
        "\n",
        "# 归一化，归一化之前，通道上的全部像素值都必须要被转成Tensor\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
        "\n",
        "# 在实际执行代码时，我们往往将数据增强和数据预处理的代码写在一起\n",
        "transform = transforms.Compose([transforms.Resize(256), # 先对尺寸进行操作\n",
        "                 transforms.RandomCrop(size=(224))，\n",
        "                 transforms.RandomHorizontalFlip(p=1)， # 再进行翻转和旋转\n",
        "\n",
        "                 transforms.RandomRotation(degrees=(-70, 70)),\n",
        "                 transforms.ToTensor()\n",
        "                 transforms.Normalize(0.5, 0.5))                \n",
        "                 ])"
      ],
      "metadata": {
        "id": "oEOPF1G0sZix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 优化算法 Adagrad\n",
        "import numpy as np\n",
        "# 假设现在有4个权重，迭代了3次\n",
        "# 第一次迭代时全部的梯度\n",
        "gt1 = np.array([[1],\n",
        "         [2],\n",
        "         [3],\n",
        "         [4]])\n",
        "\n",
        "# 第二次迭代时全部的梯度\n",
        "gt2 = np.array([[4],\n",
        "         [5],\n",
        "         [6],\n",
        "         [7]])\n",
        "\n",
        "# 第三次迭代时全部的梯度\n",
        "gt3 = np.array([[7],\n",
        "         [8],\n",
        "         [9],\n",
        "         [10]])\n",
        "\n",
        "# 第一次迭代时gt1与自己的转置相乘得到的外积\n",
        "print(gt1 * gt1.T)\n",
        "\n",
        "# t次迭代及之前，所有的gt与自己的转置相乘得到的外积\n",
        "Gt = (gt1 * gt1.T) + (gt2 * gt2.T) + (gt3 * gt3.T)\n",
        "print(Gt)\n",
        "print(np.diag(np.diagonal(Gt))) # 取对角矩阵"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp9jiZZNfsrg",
        "outputId": "a3ef813a-1e24-4bb9-fdc2-8b2b41ee48d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]\n",
            " [ 4  8 12 16]]\n",
            "[[ 66  78  90 102]\n",
            " [ 78  93 108 123]\n",
            " [ 90 108 126 144]\n",
            " [102 123 144 165]]\n",
            "[[ 66   0   0   0]\n",
            " [  0  93   0   0]\n",
            " [  0   0 126   0]\n",
            " [  0   0   0 165]]\n"
          ]
        }
      ]
    }
  ]
}