{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch深度学习11-图像数据预处理.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNCriUVw/Vxz5mcbYZVsPCr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GzpTez0514/-/blob/main/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A011_%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKl4aNXsyKdZ"
      },
      "outputs": [],
      "source": [
        "# 定义Dataset的子类\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import torch, torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random # 为了plotsamples而导入\n",
        "\n",
        "# 包含了所有图像的目录，没有具体到某一张图像\n",
        "imgpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "# 标签文件的目录\n",
        "csvpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "identity = pd.read_csv(csvpath, sep=' ', header=None)\n",
        "print(identity.head())\n",
        "\n",
        "imgdic = os.path.join(imgpath, identity.iloc[0, 0])\n",
        "print(imgdic)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将读取的标签和图像合并\n",
        "idx = 0 # 自定义\n",
        "imgpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "csvpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "imgdic = os.path.join(imgpath, identity.iloc[index, 0])\n",
        "iamge = torch.tensor(io.imread(imgdic))\n",
        "sample = (image, int(identity.iloc[index, 0]))\n",
        "print(image.shape)\n",
        "print(sample)\n",
        "# 成功读取一张图片，并将它和标签打包成一个元组"
      ],
      "metadata": {
        "id": "3GCRfDKa790Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 更换文件拓展名\n",
        "# identity是个体识别的标签\n",
        "identity2 = identity.copy()\n",
        "identity2['2'] = [x[:-3] + 'png' for x in identity2.iloc[:, 0]]\n",
        "print(identity2.head())\n",
        "imgpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "csvpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "imgdic = os.path.join(imgpath, identity2.iloc[idx, 2])\n",
        "image = torch.tensor(io.imread(imgdic))\n",
        "sample = (image, int(identity.iloc[idx, 1]))"
      ],
      "metadata": {
        "id": "6ByXEgYcJIvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 包装成类\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import torch, torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  '''\n",
        "  自定义数据集，用于读取celebA数据集中的个体识别数据的标签和图像\n",
        "  图像的格式为jpg\n",
        "  '''\n",
        "  def __init__(self, csv_file, root_dir, transform=None):\n",
        "    '''\n",
        "    参数说明：\n",
        "      csv_file:标签的具体位置\n",
        "      root_dir：所有图片所在的根目录\n",
        "      transform：选填，需要对样本进行预处理\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.identity = pd.read_csv(csv_file, sep=' ', header=None)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    # 展示数据总共有多少个样本\n",
        "    return len(self.identity)\n",
        "\n",
        "  def __info__(self):\n",
        "    print('CustomData')\n",
        "    print(f'\\t Number of samples: {len(self.identity)}')\n",
        "    print(f'\\t Number of classes: {len(np.unique(self.identity.iloc[:, 1]))}')\n",
        "    print(f'\\t root_dir: {self.root_dir}')\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # 保证idx不是一个tensor\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    # 图像目录\n",
        "    imgdic = os.path.join(self.root, self.identity.iloc[idex, 0])\n",
        "    # 提取出的，索引为idx的图像的像素值矩阵\n",
        "    image = io.imread(imgdic)\n",
        "    label = self.identity.iloc[idex, 1]\n",
        "\n",
        "    if self.transform != None:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    sample = (image, label)\n",
        "    return sample\n",
        "\n",
        "img_path = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "csv_path = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "\n",
        "data = CustomDataset(root_dir=img_path, \n",
        "           csv_file=csv_path, \n",
        "           transform=transforms.Totensor())\n",
        "\n",
        "print(data.__info__())\n",
        "print(__len__())\n",
        "\n",
        "for x,y in data:\n",
        "  print(x.shape, y)\n",
        "  break\n",
        "\n",
        "# getitem的存在令子类生成的数据能够被索引调用和查看\n",
        "data[998]\n",
        "\n",
        "# 让每个数据集随机显示5张图片\n",
        "plotsample(data)\n",
        "\n",
        "# 用来分割训练集和测试集的工具\n",
        "from torch.utils.data import random_split\n",
        "print(data.__len__())\n",
        "\n",
        "train, test = random_split(data, [700, 300], generator=torch.Generator().manual_seed(42))\n",
        "print(train.__len__()) # 分割数据集由Dataset变成了Subset, 继承自Dataset类的方法会全保留，而自己设置的方法则会失效\n",
        "print(train.__info__())\n",
        "print(test.__len__()"
      ],
      "metadata": {
        "id": "mjKoA1e4fqYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 读取标签属性，并放置到类CustomDataset_attr中\n",
        "class CustomDataset_attr(Dataset):\n",
        "  '''\n",
        "  自定义数据集，用于读取celeBA数据集中的属性识别数据的标签和图像\n",
        "  图像格式为jpg\n",
        "  '''\n",
        "  def __init__(self, csv_file, root_dir, labelname, transform=None):\n",
        "    '''\n",
        "    参数说明：\n",
        "      csv_file:标签的具体地址\n",
        "      root_dir:所有图片所在的根目录\n",
        "      transform:选填，需要对样本进行的预处理\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.attr_ = pd.read_csv(csv_path, header=None)\n",
        "    self.root_dir = root_dir\n",
        "    self.labelname = labelname\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    # 展示数据中总共有多少个样本\n",
        "    return len(self.attr_)\n",
        "\n",
        "  def __info__(self):\n",
        "    print('CustomData')\n",
        "    print(f'\\t Number of samples: {len(self.sttr_) - 1}')\n",
        "    print(f'\\t root_dir: {self.root_dir}')\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # 保证idx不是一个tensor\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    \n",
        "    self.attr_ = pd.DataFrame(self.attr_.iloc[1:, 0].str.split().tolist(),\n",
        "                  columns=self.attr_.iloc[0, 0].split())\n",
        "    \n",
        "    imgdic = os.path.join(self.root_dir, self.attr_.iloc[idx, 0]) # 图像目录\n",
        "    image = io.imread(imgdic) # 提取出的，索引为idx的图像的像素值矩阵\n",
        "    label = int(self.attr_.loc[idx, self.labelname])\n",
        "\n",
        "    if self.transform != None:\n",
        "      image = self.transform(image)\n",
        "    \n",
        "    sample = (image, label)\n",
        "    return sample\n",
        "\n",
        "imgpath = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Img\\Img_celeba.7z\\img_celeba'\n",
        "csv_path = r'C:\\学习资料文件夹\\深兰资料\\数据&论文\\WEEK10-WEEK14-CV数据包\\datasets4\\picturestotensor\\celebAsubset\\Anno\\identity_CelebA_1000.txt'\n",
        "labelname = 'Attractive'\n",
        "\n",
        "data = CustomDataset_attr(csv_path, img_path, labelname)\n",
        "print(data)\n",
        "print(data.__info__())\n",
        "print(data[500])"
      ],
      "metadata": {
        "id": "dVKeZPM6tFIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 从二维表到四维tensor\n",
        "# csv\n",
        "import pandas as pd\n",
        "data = pd.read_csv(r'........')\n",
        "\n",
        "# txt\n",
        "data = pd.read_csv(r'........', sep=' ')\n",
        "\n",
        "# 导入数据之后，将二维表格整理成更高维的数据，就可以放入卷积网络进行训练\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.random.randint(0, 255, (10, 10000)) # 假设现在是10个样本，每个样本10000个特征\n",
        "data.reshape(10, 1, 100, 100) # 可以直接使用reshape的方式将数据调整为4维\n",
        "data = torch.tensor(data) # 再放入tensor中转换格式\n",
        "plt.imshow(data.view(-1, 100, 100, 1)[0])\n",
        "print(data)"
      ],
      "metadata": {
        "id": "8kcLrv-r9S-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 多项式升维\n",
        "from sklearn.preprocessing import PolynomialFeatures as PF\n",
        "import numpy as np\n",
        "\n",
        "# 如果数据是一维的\n",
        "x = np.arange(1, 4).reshape(-1, 1)\n",
        "print(x)\n",
        "\n",
        "# 二次多项式，参数degree控制多项式的次方\n",
        "poly = PF(degree=2)\n",
        "\n",
        "# 接口transform直接调用\n",
        "x_ = poly.fit_transform(x)\n",
        "print(x_)\n",
        "\n",
        "# 三次多项式\n",
        "PF(degree=3).fit_transform(x)\n"
      ],
      "metadata": {
        "id": "eeOKf6Qp8-LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 从mat/pt/Imdb到四维tensor\n",
        "# FashionMNIST数据集就是pt格式的数据,可以直接使用torch.load进行读取\n",
        "import torch\n",
        "x, y = torch.load(r'-------------')\n",
        "print(x.shape)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "YAqMmUAZF1L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 图片数据的预处理与数据增强\n",
        "# 1、数据预处理\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "\n",
        "transform = transform.Compose([transforms.Resize(256), transforms.CenterCrop(224)])\n",
        "# 等价于\n",
        "transform = nn.Sequential(transforms.Resize(256), transforms.CenterCrop(224))\n",
        "\n",
        "# 归一化，归一化之前，通道上的全部像素值都必须要被转成Tensor\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
        "\n",
        "# 在实际执行代码时，我们往往将数据增强和数据预处理的代码写在一起\n",
        "transform = transforms.Compose([transforms.Resize(256), # 先对尺寸进行操作\n",
        "                 transforms.RandomCrop(size=(224))，\n",
        "                 transforms.RandomHorizontalFlip(p=1)， # 再进行翻转和旋转\n",
        "\n",
        "                 transforms.RandomRotation(degrees=(-70, 70)),\n",
        "                 transforms.ToTensor()\n",
        "                 transforms.Normalize(0.5, 0.5))                \n",
        "                 ])"
      ],
      "metadata": {
        "id": "oEOPF1G0sZix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 优化算法 Adagrad\n",
        "import numpy as np\n",
        "# 假设现在有4个权重，迭代了3次\n",
        "# 第一次迭代时全部的梯度\n",
        "gt1 = np.array([[1],\n",
        "         [2],\n",
        "         [3],\n",
        "         [4]])\n",
        "\n",
        "# 第二次迭代时全部的梯度\n",
        "gt2 = np.array([[4],\n",
        "         [5],\n",
        "         [6],\n",
        "         [7]])\n",
        "\n",
        "# 第三次迭代时全部的梯度\n",
        "gt3 = np.array([[7],\n",
        "         [8],\n",
        "         [9],\n",
        "         [10]])\n",
        "\n",
        "# 第一次迭代时gt1与自己的转置相乘得到的外积\n",
        "print(gt1 * gt1.T)\n",
        "\n",
        "# t次迭代及之前，所有的gt与自己的转置相乘得到的外积\n",
        "Gt = (gt1 * gt1.T) + (gt2 * gt2.T) + (gt3 * gt3.T)\n",
        "print(Gt)\n",
        "print(np.diag(np.diagonal(Gt))) # 取对角矩阵"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp9jiZZNfsrg",
        "outputId": "a3ef813a-1e24-4bb9-fdc2-8b2b41ee48d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]\n",
            " [ 4  8 12 16]]\n",
            "[[ 66  78  90 102]\n",
            " [ 78  93 108 123]\n",
            " [ 90 108 126 144]\n",
            " [102 123 144 165]]\n",
            "[[ 66   0   0   0]\n",
            " [  0  93   0   0]\n",
            " [  0   0 126   0]\n",
            " [  0   0   0 165]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 调用经典架构\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models as m\n",
        "\n",
        "print(dir(m)) # 查看models里面的类\n",
        "m.AlexNet() # 查看需要填写的参数是什么\n",
        "m.alexnet() # 将AlexNet父类的功能包含在里面，不允许对原始架构进行参数输入，但是可以进行预训练\n",
        "m.resnet18()\n",
        "\n",
        "# 在实际使用模型时，我们几乎总是直接调用小的类来进行使用\n",
        "# 查看每个类中的结构\n",
        "resnet18_ = m.resnet18()\n",
        "vgg16_ = m.vgg16()\n",
        "\n",
        "# 带有名称的，可以直接用.名称的方式进行调用。通常最外层都是具有名称的，可以直接像调用属性一样调用\n",
        "print(resnet18_.conv1)\n",
        "print(resnet18_.layer1)\n",
        "\n",
        "# 不带名称的，而前面有数字编号的，则只能使用数字编号进行调用\n",
        "print(resnet18_)\n",
        "print(resnet18_.layer1[0]) # 调用layer1层的BasicBlock\n",
        "print(resnet18_.layer1[0].conv1)\n",
        "\n",
        "print(vgg16_)\n",
        "print(vgg16_.features[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xHDN8834mNM",
        "outputId": "f0d9445f-c9cd-4684-f95c-4651534e2a0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AlexNet', 'ConvNeXt', 'DenseNet', 'EfficientNet', 'GoogLeNet', 'GoogLeNetOutputs', 'Inception3', 'InceptionOutputs', 'MNASNet', 'MobileNetV2', 'MobileNetV3', 'RegNet', 'ResNet', 'ShuffleNetV2', 'SqueezeNet', 'VGG', 'VisionTransformer', '_GoogLeNetOutputs', '_InceptionOutputs', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_utils', 'alexnet', 'convnext', 'convnext_base', 'convnext_large', 'convnext_small', 'convnext_tiny', 'densenet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'detection', 'efficientnet', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'feature_extraction', 'googlenet', 'inception', 'inception_v3', 'mnasnet', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'mobilenetv2', 'mobilenetv3', 'optical_flow', 'quantization', 'regnet', 'regnet_x_16gf', 'regnet_x_1_6gf', 'regnet_x_32gf', 'regnet_x_3_2gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_8gf', 'regnet_y_128gf', 'regnet_y_16gf', 'regnet_y_1_6gf', 'regnet_y_32gf', 'regnet_y_3_2gf', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_8gf', 'resnet', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'segmentation', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'shufflenetv2', 'squeezenet', 'squeezenet1_0', 'squeezenet1_1', 'vgg', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'video', 'vision_transformer', 'vit_b_16', 'vit_b_32', 'vit_l_16', 'vit_l_32', 'wide_resnet101_2', 'wide_resnet50_2']\n",
            "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "BasicBlock(\n",
            "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们可以根据我们自己的需要修改部分层的超参数\n",
        "# 所有的类都是基于ImageNet数据集构建，因此输入通道数都为3，输出的类别都为1000\n",
        "# 当我们更换自己的数据集的时候，就需要对输入和输出进行变化\n",
        "in_channels = 1\n",
        "out_num = 10\n",
        "print(resnet18_)\n",
        "\n",
        "# 需要替换掉整个层\n",
        "resnet18_.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "resnet18_.fc = nn.Linear(in_features=512, out_features=out_num, bias=False)\n",
        "print(resnet18_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWIs3Qy7-iBY",
        "outputId": "26a357be-5b33-4df2-c67c-6914775405b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "ResNet(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 基于经典架构自建架构\n",
        "# VGG + 残差单元\n",
        "!pip install torchinfo\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models as m\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0f0DCPwAbTt",
        "outputId": "e3d3a1c2-bf1c-4e0f-b29e-327eeda487d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 先查看网络结构，挑选我们要使用的部分\n",
        "vgg16_bn_ = m.vgg16_bn() # 初始化的参数\n",
        "print(vgg16_bn_)\n",
        "\n",
        "resnet18_ = m.resnet18()\n",
        "print(resnet18_)\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # 第一个卷积层自己写，以保证输入数据在尺寸、通道数上都正确\n",
        "    self.block1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
        "                  vgg16_bn_.features[1:3])\n",
        "    \n",
        "    # 后续的架构直接从经典架构中选\n",
        "    # 对尺寸很小的数据集而言，我们的深度根本就不深，因此可以试着在特征图数量上有所增加\n",
        "    self.block2 = vgg16_bn_.features[7:14]\n",
        "    self.block3 = resnet18_.layer3\n",
        "    # 自适应平均池化+线性层，此处都与残差网络一致\n",
        "    self.avgpool = resnet18_.avgpool\n",
        "    # 输出的线性层自己写，以确保输出的类别数量正确\n",
        "    self.fc = nn.Linear(in_features=256, out_features=10, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block1(x)\n",
        "    x = self.block3(self.block2(x))\n",
        "    x = x.view(-1, 256)\n",
        "    x = self.fc(x)\n",
        "\n",
        "data = torch.ones(10, 1, 28, 28)\n",
        "net = MyNet()\n",
        "net(data)\n",
        "\n",
        "# 查看自己构建的网络和参数量\n",
        "summary(net, input_size=(10, 1, 28, 28), depth=1, device='cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LATHt1EvBm6I",
        "outputId": "2c221e4d-e5a3-4511-e900-d9335dcb5f29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MyNet                                    --                        --\n",
              "├─Sequential: 1-1                        [10, 64, 28, 28]          768\n",
              "├─Sequential: 1-2                        [10, 128, 14, 14]         221,952\n",
              "├─Sequential: 1-3                        [10, 256, 7, 7]           2,099,712\n",
              "├─Linear: 1-4                            [490, 10]                 2,570\n",
              "==========================================================================================\n",
              "Total params: 2,325,002\n",
              "Trainable params: 2,325,002\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 2.77\n",
              "==========================================================================================\n",
              "Input size (MB): 0.03\n",
              "Forward/backward pass size (MB): 50.22\n",
              "Params size (MB): 9.30\n",
              "Estimated Total Size (MB): 59.55\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.resnet import resnet18\n",
        "# 实现预训练\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models as m\n",
        "\n",
        "resnet18_ = m.resnet18()\n",
        "#print(resnet18_)\n",
        "\n",
        "rs18pt = m.resnet18(pretrained=True) \n",
        "print(resnet18_.conv1.weight[0]) # 初始化的参数，准备好训练\n",
        "print(rs18pt.conv1.weight[0]) # 经过预训练的参数\n",
        "\n",
        "# 属性requires_grad为true，意味着可以参与反向传播\n",
        "# 预训练的参数刚被导入时，都是默认可以被训练的\n",
        "rs18pt.conv1.weight[0].requires_grad # True\n",
        "\n",
        "# 将导入的预训练模型中所有的参数锁住\n",
        "for param in rs18pt.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "rs18pt.conv1.weight[0].requires_grad # False\n",
        "\n",
        "# 使用新的层覆盖原来的层\n",
        "rs18pt.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "# 新生成的层默认requires_grad=True\n",
        "# 因此在锁定模型中的参数后，只要覆盖掉原来的层，或者在原来的层之后加上新的层，新的层默认就是可以训练的\n",
        "# 但是新的层将会覆盖掉原来层已经训练好的参数，所以我们一般不对conv1进行覆盖\n",
        "rs18pt.conv1.weight.requires_grad # True\n",
        "\n",
        "\n",
        "# 按照这一逻辑定义架构\n",
        "# 让18层残差网络的前2个layers都被冻结，后面两个layers从0开始训练\n",
        "resnet18_ = m.resnet18()\n",
        "rs18pt = m.resnet18(pretrained=True)\n",
        "fcin = rs18pt.fc.in_features\n",
        "\n",
        "for param in rs18pt.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "class MyNet_pretrained(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # 迁移层（锁住）\n",
        "    self.pretrained_ = nn.Sequential(rs18pt.conv1,\n",
        "                     rs18pt.bn1,\n",
        "                     rs18pt.relu,\n",
        "                     rs18pt.maxpool,\n",
        "                     rs18pt.layer1,\n",
        "                     rs18pt.layer2)\n",
        "    # 允许训练的层\n",
        "    self.train_ = nn.Sequential(resnet18_.layer3,\n",
        "                   resnet18_.layer4,\n",
        "                   resnet18_.avgpool)\n",
        "    \n",
        "    # 输出的线性层自己写，以确保输出的类别数量正确\n",
        "    self.fc = nn.Linear(in_features=fcin, out_features=10, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pretrained(x)\n",
        "    x = self.train_(x)\n",
        "    x = x.view(-1, 512)\n",
        "    x = self.fc(x)\n",
        "  \n",
        "net = MyNet_pretrained()\n",
        "print(net.pretrained_)\n",
        "print(net.train_)\n",
        "print(net.pretrained_[0].weight.requires_grad) # False\n",
        "print(net.train_[0][0].conv1.weight.requires_grad) # True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joH1lm3tMX6O",
        "outputId": "b18ada1e-e78c-492d-8506-4b26d0356814"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 8.7647e-03,  1.9748e-02, -1.0925e-03, -4.2401e-03,  2.6497e-02,\n",
            "          -2.9407e-02,  1.2824e-02],\n",
            "         [ 3.0578e-03, -4.7486e-02,  2.3529e-02,  3.2250e-04,  7.0533e-03,\n",
            "           5.1749e-03, -8.7045e-03],\n",
            "         [ 2.9702e-03,  1.8962e-02, -2.2133e-02, -2.8205e-02,  1.5407e-02,\n",
            "          -2.7863e-03, -1.8765e-02],\n",
            "         [ 1.0422e-02, -8.7624e-03,  3.7211e-02, -7.0412e-03,  2.0084e-02,\n",
            "          -2.8198e-02, -2.6693e-02],\n",
            "         [-3.4844e-02, -2.1606e-02, -6.8359e-02, -3.3809e-04,  2.6320e-02,\n",
            "          -6.6771e-03,  3.2061e-02],\n",
            "         [ 6.2157e-03, -8.2307e-03,  2.0330e-02, -3.8204e-03, -5.0498e-02,\n",
            "           6.4256e-03, -3.6002e-02],\n",
            "         [ 5.3977e-02,  7.9113e-03, -3.8774e-02,  3.2602e-02,  2.4778e-03,\n",
            "          -1.0423e-02, -1.6586e-03]],\n",
            "\n",
            "        [[ 2.5950e-03, -1.7084e-02,  5.8692e-02, -7.0571e-03,  2.6684e-02,\n",
            "          -2.4464e-02,  2.1102e-02],\n",
            "         [ 6.7129e-03, -1.4151e-02, -8.6404e-03, -4.2838e-03,  2.8683e-02,\n",
            "          -1.8892e-02,  3.5642e-02],\n",
            "         [ 1.5707e-02,  2.1753e-02,  5.9266e-04, -1.8181e-02,  1.4295e-02,\n",
            "          -2.7121e-02,  1.9935e-02],\n",
            "         [ 5.7611e-03, -9.9323e-03, -9.8819e-03,  1.7670e-02, -1.4261e-02,\n",
            "          -5.2725e-03,  1.8148e-03],\n",
            "         [ 3.1010e-02,  1.2138e-02, -2.1110e-02,  3.0598e-02, -2.7736e-02,\n",
            "          -1.7676e-02, -4.5942e-03],\n",
            "         [-9.7142e-03,  2.2194e-02, -3.8876e-02,  1.1393e-02,  3.3421e-02,\n",
            "          -5.1392e-02,  1.3949e-02],\n",
            "         [ 3.7234e-02,  1.2164e-02, -6.3015e-02,  1.5412e-02, -1.3291e-02,\n",
            "          -1.0702e-02,  1.8320e-03]],\n",
            "\n",
            "        [[ 4.4546e-03, -2.4053e-02, -1.1510e-02,  3.2038e-02, -3.6212e-02,\n",
            "          -1.7937e-02,  1.7419e-02],\n",
            "         [-4.4038e-03, -1.8657e-03,  1.7594e-04, -5.1690e-02,  1.5526e-03,\n",
            "          -3.6048e-05, -3.5587e-02],\n",
            "         [-2.0694e-02,  1.1712e-02, -3.9874e-02, -1.6171e-03, -4.8830e-02,\n",
            "          -2.8307e-02,  1.3278e-02],\n",
            "         [ 1.0413e-02, -2.4861e-02,  2.5908e-02,  3.5917e-02, -2.3041e-03,\n",
            "           5.2404e-02, -9.3266e-04],\n",
            "         [ 2.2245e-02,  4.3259e-02,  3.1811e-02, -6.6704e-03, -2.2483e-02,\n",
            "          -8.1009e-03,  8.2955e-03],\n",
            "         [ 1.4224e-02,  1.4139e-02,  2.2221e-02,  2.8578e-02, -1.3212e-02,\n",
            "          -3.8786e-02,  1.1816e-02],\n",
            "         [ 3.3739e-02,  9.6152e-03, -1.2488e-02, -6.3941e-03, -3.4937e-02,\n",
            "          -1.0693e-03,  4.7656e-03]]], grad_fn=<SelectBackward0>)\n",
            "tensor([[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  7.4841e-02,  5.6615e-02,\n",
            "           1.7083e-02, -1.2694e-02],\n",
            "         [ 1.1083e-02,  9.5276e-03, -1.0993e-01, -2.8050e-01, -2.7124e-01,\n",
            "          -1.2907e-01,  3.7424e-03],\n",
            "         [-6.9434e-03,  5.9089e-02,  2.9548e-01,  5.8720e-01,  5.1972e-01,\n",
            "           2.5632e-01,  6.3573e-02],\n",
            "         [ 3.0505e-02, -6.7018e-02, -2.9841e-01, -4.3868e-01, -2.7085e-01,\n",
            "          -6.1282e-04,  5.7602e-02],\n",
            "         [-2.7535e-02,  1.6045e-02,  7.2595e-02, -5.4102e-02, -3.3285e-01,\n",
            "          -4.2058e-01, -2.5781e-01],\n",
            "         [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  2.3897e-01,  4.1384e-01,\n",
            "           3.9359e-01,  1.6606e-01],\n",
            "         [-1.3736e-02, -3.6746e-03, -2.4084e-02, -6.5877e-02, -1.5070e-01,\n",
            "          -8.2230e-02, -5.7828e-03]],\n",
            "\n",
            "        [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  3.6812e-02,  3.2521e-02,\n",
            "           6.6221e-04, -2.5743e-02],\n",
            "         [ 4.5687e-02,  3.3603e-02, -1.0453e-01, -3.0885e-01, -3.1253e-01,\n",
            "          -1.6051e-01, -1.2826e-03],\n",
            "         [-8.3730e-04,  9.8420e-02,  4.0210e-01,  7.7035e-01,  7.0789e-01,\n",
            "           3.6887e-01,  1.2455e-01],\n",
            "         [-5.8427e-03, -1.2862e-01, -4.2071e-01, -5.9270e-01, -3.8285e-01,\n",
            "          -4.2407e-02,  6.1568e-02],\n",
            "         [-5.5926e-02, -5.2239e-03,  2.7081e-02, -1.5159e-01, -4.6178e-01,\n",
            "          -5.7080e-01, -3.6552e-01],\n",
            "         [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  3.1815e-01,  5.4636e-01,\n",
            "           4.8276e-01,  1.9867e-01],\n",
            "         [ 5.3051e-03,  6.6938e-03, -1.7254e-02, -6.9806e-02, -1.4822e-01,\n",
            "          -7.7248e-02,  7.2183e-04]],\n",
            "\n",
            "        [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  8.9755e-02,  8.9177e-02,\n",
            "           3.3655e-02, -2.0102e-02],\n",
            "         [ 1.5398e-02, -1.8648e-02, -1.2591e-01, -2.9553e-01, -2.5342e-01,\n",
            "          -1.2980e-01, -2.7975e-02],\n",
            "         [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  4.3010e-01,  3.4872e-01,\n",
            "           1.0433e-01,  1.8413e-02],\n",
            "         [ 2.6426e-02, -2.5990e-02, -1.9699e-01, -2.6806e-01, -1.0524e-01,\n",
            "           7.8577e-02,  1.2077e-01],\n",
            "         [-2.8356e-02,  1.8404e-02,  9.8647e-02,  6.1242e-02, -1.1740e-01,\n",
            "          -2.5760e-01, -1.5451e-01],\n",
            "         [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  5.7450e-02,  2.4141e-01,\n",
            "           2.4345e-01,  1.1796e-01],\n",
            "         [ 7.4684e-04,  7.7677e-04, -1.0050e-02, -5.5153e-02, -1.4865e-01,\n",
            "          -1.1754e-01, -3.8350e-02]]], grad_fn=<SelectBackward0>)\n",
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (2): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            ")\n",
            "False\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}