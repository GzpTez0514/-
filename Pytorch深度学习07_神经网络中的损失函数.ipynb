{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch深度学习07-神经网络中的损失函数.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNz6ByWocUuxvcbPt389rA6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GzpTez0514/-/blob/main/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A007_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQA_-jdPD4Jr",
        "outputId": "cd7a00e4-26e7-498a-f679-6dd879028138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4869)\n",
            "tensor(2.4869)\n",
            "tensor(124.3458)\n"
          ]
        }
      ],
      "source": [
        "# 回归：误差平方和\n",
        "from torch.nn import MSELoss\n",
        "import torch\n",
        "\n",
        "torch.random.manual_seed(420)\n",
        "yhat = torch.randn(size=(50,), dtype=torch.float32)\n",
        "y = torch.randn(size=(50,), dtype=torch.float32)\n",
        "\n",
        "# 均方误差\n",
        "criterion = MSELoss() # 实例化\n",
        "loss = criterion(yhat, y)\n",
        "print(loss)\n",
        "\n",
        "criterion = MSELoss(reduction='mean') # 实例化，输出MSE\n",
        "loss = criterion(yhat, y)\n",
        "print(loss)\n",
        "\n",
        "criterion = MSELoss(reduction='sum') # 实例化。输出SSE\n",
        "loss = criterion(yhat, y)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 用Tensor二分类交叉熵损失函数\n",
        "import torch\n",
        "\n",
        "N = 3 * pow(10, 3)\n",
        "torch.random.manual_seed(420)\n",
        "X = torch.rand((N, 4), dtype=torch.float32)\n",
        "w = torch.rand((4, 1), dtype=torch.float32, requires_grad=True)\n",
        "y = torch.randint(low=0, high=2, size=(N, 1), dtype=torch.float32)\n",
        "\n",
        "zhat = torch.mm(X, w)\n",
        "sigma = torch.sigmoid(zhat)\n",
        "Loss = -(1 / N) * torch.sum((1 - y) * torch.log(1 - sigma) + y * torch.log(sigma))\n",
        "print(Loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IVSsHKjUzES",
        "outputId": "917210bb-4978-46d8-9114-01007de7125c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7962, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 用PyTorch中的类实现二分类交叉熵损失\n",
        "import torch.nn as nn\n",
        "N = 3 * pow(10, 3)\n",
        "torch.random.manual_seed(420)\n",
        "X = torch.rand((N, 4), dtype=torch.float32)\n",
        "w = torch.rand((4, 1), dtype=torch.float32, requires_grad=True)\n",
        "y = torch.randint(low=0, high=2, size=(N, 1), dtype=torch.float32)\n",
        "zhat = torch.mm(X, w)\n",
        "sigma = torch.sigmoid(zhat)\n",
        "criterion = nn.BCELoss()\n",
        "loss = criterion(sigma, y)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9gww_RlcNpn",
        "outputId": "4f6f7b59-6f01-4ce0-b508-ebb1f744b92f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7962, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "loss = criterion(zhat, y)\n",
        "print(loss)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "loss = criterion(zhat, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT90yKfAhZQ7",
        "outputId": "1d5d5c19-3d12-4c8c-ff37-f6b57aaaa4b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7962, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
        "criterion = BCEWithLogitsLoss(reduction='mean') # 求解所有样本的平均损失\n",
        "loss = criterion(zhat, y)\n",
        "print(loss)\n",
        "\n",
        "criterion = BCEWithLogitsLoss(reduction='sum') # 求解样本的总体损失\n",
        "loss = criterion(zhat, y)\n",
        "print(loss)\n",
        "\n",
        "criterion = BCEWithLogitsLoss(reduction='none') # 不对结果做任何运算\n",
        "loss = criterion(zhat, y)\n",
        "print(loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15QsQvkEk1Jd",
        "outputId": "89c76938-05dd-42b6-f4a0-9d132694c264"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7962, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(2388.5840, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor([[0.3075],\n",
            "        [0.3073],\n",
            "        [0.9198],\n",
            "        ...,\n",
            "        [0.3876],\n",
            "        [0.4536],\n",
            "        [0.3442]], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# functional库中的计算函数\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# 直接调用functional库中的计算函数\n",
        "loss = F.binary_cross_entropy_with_logits(zhat, y)\n",
        "print(loss)\n",
        "\n",
        "loss = F.binary_cross_entropy(sigma, y)\n",
        "print(loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2g4m75gx5MG",
        "outputId": "7d2e2065-ee67-4e1b-c923-4952b5465f2f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7962, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.7962, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 多分类交叉熵损失函数\n",
        "# 在pytorch中实现交叉熵函数的时候，有两种办法\n",
        "# 调用LogSoftmax和NLLLoss实现\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "N = 3 * pow(10, 2)\n",
        "torch.random.manual_seed(420)\n",
        "X = torch.rand((N, 4), dtype=torch.float32)\n",
        "w = torch.rand((4, 3), dtype=torch.float32, requires_grad=True)\n",
        "y = torch.randint(low=0, high=3, size=(N,), dtype=torch.float32)\n",
        "zhat = torch.mm(X, w)\n",
        "\n",
        "# 从这里开始调用softmax和NLLLoss\n",
        "logsm = nn.LogSoftmax(dim=1)\n",
        "logsigma = logsm(zhat)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "# 由于交叉熵损失需要将标签化转换为独热编码。因此不接受浮点数作为标签的输入\n",
        "# 对NLLLoss而言，需要输入logsigma\n",
        "loss = criterion(logsigma, y.long())\n",
        "print(y)\n",
        "print(loss)\n",
        "\n",
        "# 更简便的方法，直接调用CrossEntropyLoss()\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "# 对打包好的CrossEntropyLoss而言，只需要输入zhat\n",
        "loss = criterion(zhat, y.long())\n",
        "print(loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s-FqIXqGg-6",
        "outputId": "ef33a857-a557-4d70-f499-a3688458672e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 2., 2., 1., 0., 1., 0., 2., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        0., 0., 2., 0., 0., 1., 1., 0., 2., 1., 1., 1., 2., 2., 2., 1., 0., 0.,\n",
            "        2., 2., 2., 1., 0., 2., 0., 2., 0., 2., 2., 0., 0., 0., 0., 1., 2., 0.,\n",
            "        2., 0., 0., 1., 2., 2., 1., 0., 1., 1., 2., 1., 0., 2., 0., 0., 2., 1.,\n",
            "        2., 1., 0., 1., 1., 0., 1., 0., 2., 0., 2., 0., 0., 0., 2., 0., 1., 1.,\n",
            "        1., 1., 2., 0., 2., 2., 2., 0., 0., 1., 2., 2., 1., 2., 0., 2., 0., 2.,\n",
            "        0., 0., 1., 2., 0., 0., 2., 2., 0., 1., 1., 0., 2., 1., 2., 1., 1., 0.,\n",
            "        2., 2., 1., 0., 0., 0., 1., 1., 2., 2., 1., 0., 2., 0., 2., 2., 0., 2.,\n",
            "        2., 1., 2., 2., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 2., 1.,\n",
            "        1., 2., 2., 2., 0., 2., 1., 1., 1., 0., 2., 2., 1., 0., 1., 1., 1., 2.,\n",
            "        2., 1., 1., 1., 0., 1., 2., 2., 1., 2., 2., 0., 2., 2., 2., 2., 0., 1.,\n",
            "        2., 2., 1., 0., 2., 2., 1., 1., 2., 1., 1., 2., 1., 2., 1., 1., 1., 2.,\n",
            "        2., 1., 2., 1., 0., 2., 1., 2., 1., 1., 1., 0., 2., 1., 0., 2., 1., 0.,\n",
            "        0., 0., 0., 0., 2., 2., 0., 2., 1., 0., 1., 2., 1., 2., 1., 1., 0., 1.,\n",
            "        1., 1., 0., 2., 1., 0., 0., 2., 0., 1., 1., 2., 2., 2., 1., 1., 1., 0.,\n",
            "        0., 2., 0., 1., 0., 1., 2., 1., 1., 0., 0., 0., 2., 0., 0., 1., 0., 1.,\n",
            "        0., 0., 1., 0., 0., 2., 2., 1., 1., 1., 2., 0.])\n",
            "tensor(1.1591, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1591, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    }
  ]
}