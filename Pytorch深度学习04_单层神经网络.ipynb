{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch深度学习04-单层神经网络.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKQw1TAtZwYbm8Y9ckxTQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GzpTez0514/-/blob/main/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A004_%E5%8D%95%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy5DbdvWamfG",
        "outputId": "43049f3e-a564-4025-d63e-55ac1cb76ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2000, -0.0500, -0.0500,  0.1000])\n",
            "tensor([-0.2000, -0.0500, -0.0500,  0.1000])\n",
            "tensor([ True, False, False, False])\n",
            "tensor([-0.200000002980232238769531250000, -0.049999997019767761230468750000,\n",
            "        -0.049999997019767761230468750000,  0.100000008940696716308593750000])\n",
            "tensor([-0.200000002980232238769531250000, -0.050000000745058059692382812500,\n",
            "        -0.050000000745058059692382812500,  0.100000001490116119384765625000])\n",
            "tensor([ True, False, False, False])\n"
          ]
        }
      ],
      "source": [
        "# tensor实现单层神经网络的正向传播\n",
        "import torch\n",
        "X = torch.tensor([[1, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "z = torch.tensor([-0.2, -0.05, -0.05, 0.1])\n",
        "w = torch.tensor([-0.2, 0.15, 0.15])\n",
        "\n",
        "def Linear(X, w):\n",
        "  zhat = torch.mv(X, w)\n",
        "  return zhat\n",
        "\n",
        "zhat = Linear(X, w)\n",
        "print(z)\n",
        "print(zhat)\n",
        "print(z == zhat)\n",
        "\n",
        "SSE = sum((zhat - z) ** 2)\n",
        "# 设置显示精度，再来看zhat与z\n",
        "torch.set_printoptions(precision=30)\n",
        "print(zhat)\n",
        "print(z)\n",
        "# 精度问题在tensor维度很高，数字很大时，也会变得很大，所以pytorch设置了64位浮点数来尽量减轻精度问题\n",
        "# 如果你希望能够无视掉非常小的区别，而让两个张量的比较结果展示为true，可以使用以下代码\n",
        "torch.allclose(zhat, z)\n",
        "print(zhat == z)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用nn.Linear来实现单层回归神经网络：\n",
        "X = torch.tensor([[0, 0], [1, 0], [0, 1], [1, 1]], dtype=torch.float32)\n",
        "output = torch.nn.Linear(2, 1)\n",
        "zhat = output(X)\n",
        "print(zhat)\n",
        "print(output.weight) # 查看生成的w\n",
        "print(output.bias) # 查看生成的b\n",
        "\n",
        "# 其中，w是必然会生成的，b是我们可以控制是否要生成的\n",
        "output = torch.nn.Linear(2, 1, bias=False)\n",
        "print(output.weight)\n",
        "print(output.bias)\n",
        "\n",
        "# 由于w和b是随机生成的，所以同样的代码多次运行后的结果是不一致的。如果我们希望控制随机性，则可以使用torch中的random类\n",
        "torch.random.manual_seed(420) # 手动设置随机数种子\n",
        "output = torch.nn.Linear(2, 1)\n",
        "zhat = output(X)\n",
        "print(zhat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgGcX2t_lIrP",
        "outputId": "403a1892-02f5-47ec-848a-ef0f4513bff8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.487291485071182250976562500000],\n",
            "        [-1.048992395401000976562500000000],\n",
            "        [-0.703015983104705810546875000000],\n",
            "        [-1.264716863632202148437500000000]], grad_fn=<AddmmBackward0>)\n",
            "Parameter containing:\n",
            "tensor([[-0.561700880527496337890625000000, -0.215724512934684753417968750000]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.487291485071182250976562500000], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[0.545342266559600830078125000000, 0.265266954898834228515625000000]],\n",
            "       requires_grad=True)\n",
            "None\n",
            "torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 二分类神经网络：逻辑回归\n",
        "# 特征\n",
        "X = torch.tensor([[1, 0, 0], \n",
        "          [1, 1, 0],\n",
        "          [1, 0, 1], \n",
        "          [1, 1, 1]], dtype=torch.float32)\n",
        "# 标签\n",
        "andgate = torch.tensor([0, 0, 0, 1], dtype=torch.float32)\n",
        "w = torch.tensor([-0.2, 0.15, 0.15], dtype=torch.float32)\n",
        "\n",
        "def LogisticR(X, w):\n",
        "  # 先执行线性回归过程\n",
        "  zhat = torch.mv(X, w)\n",
        "  # sigma = 1 / (1 + torch.exp(-zhat))\n",
        "  sigma = torch.sigmoid(zhat)\n",
        "  # 设置阈值为0.5， 使用列表推导式将值转化为0和1\n",
        "  andhat = torch.tensor([int(x) for x in sigma >= 0.5], dtype=torch.float32)\n",
        "  return sigma, andhat\n",
        "\n",
        "sigma, andhat = LogisticR(X, w)\n",
        "print(sigma)\n",
        "print(andhat)\n",
        "print(andhat == andgate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEBtM-JooqxH",
        "outputId": "be142873-372f-4bf2-ba3f-71b33448df34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.450166016817092895507812500000, 0.487502634525299072265625000000,\n",
            "        0.487502634525299072265625000000, 0.524979174137115478515625000000])\n",
            "tensor([0., 0., 0., 1.])\n",
            "tensor([True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 符号函数sign，ReLU, Tanh\n",
        "# 使用阶跃函数来处理‘与门'的数据\n",
        "import torch\n",
        "X = torch.tensor([[1, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "andgate = torch.tensor([0, 0, 0, 1], dtype=torch.float32)\n",
        "w = torch.tensor([-0.2, 0.15, 0.15], dtype=torch.float32)\n",
        "\n",
        "def LinearRwithsign(X, w):\n",
        "  zhat = torch.mv(X, w)\n",
        "  anhat = torch.tensor([int(x) for x in zhat >= 0], dtype=torch.float32)\n",
        "  return zhat, andhat\n",
        "zhat, andhat = LinearRwithsign(X, w)\n",
        "print(zhat)\n",
        "print(andhat)\n",
        "print(andhat == andgate)\n",
        "\n",
        "# ReLU 整流线型单元函数，ReLU提供了一个很简单的非线性变换：当输入的自变量大于0时，直接输出该值，当输入的自变量小于等于0时，输出0\n",
        "# tanh 是双曲正切函数，与sigmoid相似，它能够将数值压缩到(-1,1)区间内"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC-uqY5iLVyS",
        "outputId": "d7fc424f-01a9-4828-bdbe-993384ad3c12"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.200000002980232238769531250000, -0.049999997019767761230468750000,\n",
            "        -0.049999997019767761230468750000,  0.100000008940696716308593750000])\n",
            "tensor([0., 0., 0., 1.])\n",
            "tensor([True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.functional实现单层二分类神经网络的正向传播\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "X = torch.tensor([[0, 0], [1, 0], [0, 1], [1, 1]], dtype=torch.float32)\n",
        "torch.random.manual_seed(420) # 人工设置随机种子\n",
        "dense = torch.nn.Linear(2, 1)\n",
        "zhat = dense(X)\n",
        "sigma = F.sigmoid(zhat)\n",
        "y = [int(x) for x in sigma > 0.5]\n",
        "print(y)\n",
        "# 在PyTorch中，我们可以从functional模块里找出大部分之前我们提到的函数，来看看ReLU、Tanh以及Sign函数都是如何使用PyTorch实现的\n",
        "torch.random.manual_seed(420)\n",
        "dense = torch.nn.Linear(2, 1)\n",
        "zhat = dense(X)\n",
        "\n",
        "# 符号函数sign\n",
        "sign = torch.sign(zhat)\n",
        "y = [int(x) for x in sign > 0]\n",
        "print(y)\n",
        "# ReLU\n",
        "F.relu(zhat)\n",
        "# tanh\n",
        "torch.tanh(zhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF_UsdLIWQxW",
        "outputId": "6889094f-8421-44ef-bfea-1d4e18988733"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1]\n",
            "[1, 1, 1, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5869],\n",
              "        [0.8022],\n",
              "        [0.2424],\n",
              "        [0.5910]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch中的softmax函数\n",
        "# 对于单一的样本，假定一组巨大的Z\n",
        "import torch\n",
        "Z = torch.tensor([1010, 1000, 990], dtype=torch.float32)\n",
        "softmax = torch.exp(Z) / torch.sum(torch.exp(Z))\n",
        "print(softmax) # tensor([nan, nan, nan]) 溢出\n",
        "\n",
        "Z = torch.tensor([1010, 1000, 990], dtype=torch.float32)\n",
        "softmax = torch.softmax(Z, 0)\n",
        "print(softmax) # tensor([9.9995e-01, 4.5398e-05, 2.0611e-09])\n",
        "\n",
        "# softmax函数只能对单一维度进行计算，它只能够识别单一维度上的不同类别，但我们输入softmax的张量,却可能是一个很高维的张量\n",
        "s = torch.tensor([[[1, 2], \n",
        "           [3, 4],\n",
        "           [5, 6],\n",
        "           [5, 6], \n",
        "           [7, 8], \n",
        "           [9, 10]]], dtype=torch.float32)\n",
        "print(s.ndim) # 3\n",
        "print(s.shape) # torch.Size([1, 6, 2])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA-9iMRd3T3H",
        "outputId": "41614d39-347f-4d6e-d09a-cfac9c265738"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([nan, nan, nan])\n",
            "tensor([9.9995e-01, 4.5398e-05, 2.0611e-09])\n",
            "3\n",
            "torch.Size([1, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用nn.Linear与functional实现多分类神经网络的正向传播\n",
        "from torch.nn import functional as F\n",
        "x = torch.tensor([[0, 0], [1, 0], [0, 1], [1, 1]], dtype=torch.float32)\n",
        "torch.random.manual_seed(420)\n",
        "dense = torch.nn.Linear(2, 3) # 此时，输出层上的神经元个数是3个，因此应该是（2,3）\n",
        "zhat = dense(x)\n",
        "sigma = F.softmax(zhat, dim=1) # 此时需要进行加和的维度是1\n",
        "print(sigma)\n",
        "print(sigma.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Squu2Q0JFi2h",
        "outputId": "2f5c1d35-9616-4bc5-ccf1-b7950ef8fdc9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4623, 0.3494, 0.1883],\n",
            "        [0.4598, 0.4422, 0.0980],\n",
            "        [0.4896, 0.3229, 0.1875],\n",
            "        [0.4902, 0.4115, 0.0983]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1, 0, 0],\n",
        "          [1, 1, 0],\n",
        "          [1, 0, 1],\n",
        "          [1, 1, 1]], dtype=torch.float32)\n",
        "andgate = torch.tensor([0, 0, 0, 1], dtype=torch.float32)\n",
        "\n",
        "# 定义w\n",
        "w = torch.tensor([-0.2, 0.15, 0.15], dtype=torch.float32)\n",
        "\n",
        "def LogisticR(X, w):\n",
        "  zhat = torch.mv(X, w)\n",
        "  sigma = torch.sigmoid(zhat)\n",
        "  andhat = torch.tensor([int(i) for i in sigma >= 0.5], dtype=torch.float32)\n",
        "  return sigma, andhat\n",
        "\n",
        "sigma, andhat = LogisticR(X, w)\n",
        "print(sigma)\n",
        "print(andhat)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDUseS3VJzkO",
        "outputId": "7a5744a1-f77f-4d29-aad7-e0e36b933a90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4502, 0.4875, 0.4875, 0.5250])\n",
            "tensor([0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 可以通过python中的matplotlib代码将数据可视化\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('seaborn-whitegrid') # 设置图像的风格\n",
        "sns.set_style('white')\n",
        "plt.figure(figsize=(5, 3)) # 设置画布大小\n",
        "plt.title('andgate', fontsize=16) # 设置图像标题\n",
        "plt.scatter(X[:, 1], X[:, 2], c=andgate, cmap='rainbow') # 绘制散点图\n",
        "plt.xlim(-1, 3) # 设置横纵坐标尺寸\n",
        "plt.ylim(-1, 3)\n",
        "plt.grid(alpha=0.4, axis='y') # 显示背景中的网格\n",
        "plt.gca().spines['top'].set_alpha(0.0) # 让上方和右侧的坐标轴被隐藏\n",
        "plt.gca().spines['right'].set_alpha(0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "1REIr3wLMSw8",
        "outputId": "93aa0516-92d5-4ba7-d61c-7a77d5cc09f3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用阶跃函数作为联系函数替代sigmoid来对与门数据进行分类\n",
        "X = torch.tensor([[1, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "andgate = torch.tensor([0, 0, 0, 1], dtype=torch.float32)\n",
        "\n",
        "def AND(X, w):\n",
        "  w = torch.tensor([-0.2,0.15, 0.15], dtype = torch.float32)\n",
        "  zhat = torch.mv(X, w)\n",
        "  andhat = torch.tensor([int(i) for i in zhat >= 0], dtype=torch.float32)\n",
        "  return andhat\n",
        "\n",
        "andhat = AND(X, w)\n",
        "print(andhat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LusIeTqOUcxC",
        "outputId": "0bc6bbf9-e8c9-4188-dd02-5bc891235dbd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1, 0, 0], [1, 1, 0], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "orgate = torch.tensor([0, 1, 1, 1], dtype=torch.float32)\n",
        "\n",
        "def orgate(X, w):\n",
        "  w = torch.tensor([-0.08, 0.15, 0.15], dtype=torch.float32)\n",
        "  zhat = torch.mv(X, w)\n",
        "  orhat = torch.tensor([int(i) for i in zhat >= 0], dtype=torch.float32)\n",
        "  return orhat\n",
        "\n",
        "orhat = orgate(X, w)\n",
        "print(orhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtVDTO96Xh5_",
        "outputId": "a6630d0b-6da2-47ca-ad45-266996416266"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kPbnmIIZgBO1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}