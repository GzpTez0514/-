{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GzpTez0514/-/blob/main/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A010_%E6%9E%84%E7%AD%91%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzkK_G7AVgaO",
        "outputId": "2a6d728c-fc2d-4fb0-d50e-9859057a6eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 6, 26, 26])\n",
            "torch.Size([10, 4, 24, 24])\n"
          ]
        }
      ],
      "source": [
        "# 卷积层\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "data = torch.ones(size=(10, 3, 28, 28)) # 10张尺寸为28*28的，拥有3个通道的图像\n",
        "conv1 = nn.Conv2d(in_channels=3, \n",
        "          out_channels=6, # 全部通道的扫描值被合并，6个卷积核形成6个feature map\n",
        "          kernel_size=3 # 表示3x3的卷积核\n",
        "          )\n",
        "\n",
        "conv2 = nn.Conv2d(in_channels=6, # 对下一层网络来说，输入的是上层生成的6个feature map\n",
        "          out_channels=4, # 全部特征图的扫描值被合并，4个卷积核形成4个新的feature map\n",
        "          kernel_size=3)\n",
        "\n",
        "print(conv1(data).shape)\n",
        "print(conv2(conv1(data)).shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFgCfH5zWkKU"
      },
      "outputs": [],
      "source": [
        "# 特征图的尺寸 （H + 2P -K）/ S + 1\n",
        "data = torch.ones(size=(10, 3, 28, 28))\n",
        "conv1 = nn.Conv2d(3, 6, 3)\n",
        "conv2 = nn.Conv2d(6, 4, 3)\n",
        "conv3 = nn.Conv2d(4, 16, 5, stride=2, padding=1) \n",
        "conv4 = nn.Conv2d(16, 3, 5, stride=3, padding=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16的复现\n",
        "# (卷积x2 + 池化) x2 -> (卷积x3 + 池化) x3 —> FC层x3 每组卷积+池化算一个block\n",
        "!pip install torchinfo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torchinfo import summary\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # block1\n",
        "    self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # block2\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # block3\n",
        "    self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "    self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "    self.conv7 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "    self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # block4\n",
        "    self.conv8 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "    self.conv9 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.conv10 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # block5\n",
        "    self.conv11 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.conv13 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.pool5 = nn.MaxPool2d(2,2)\n",
        "\n",
        "    # FC层\n",
        "    self.linear1 = nn.Linear(512*7*7, 4096)\n",
        "    self.linear2 = nn.Linear(4096, 4096)\n",
        "    self.linear3 = nn.Linear(4096, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.pool2(x)\n",
        "\n",
        "    x = F.relu(self.conv5(x))\n",
        "    x = F.relu(self.conv6(x))\n",
        "    x = F.relu(self.conv7(x))\n",
        "    x = self.pool3(x)\n",
        "\n",
        "    x = F.relu(self.conv8(x))\n",
        "    x = F.relu(self.conv9(x))\n",
        "    x = F.relu(self.conv10(x))\n",
        "    x = self.pool4(x)\n",
        "\n",
        "    x = F.relu(self.conv11(x))\n",
        "    x = F.relu(self.conv12(x))\n",
        "    x = F.relu(self.conv13(x))\n",
        "    x = self.pool5(x)\n",
        "    \n",
        "    x = x.view(-1, 512*7*7)\n",
        "\n",
        "    x = F.relu(self.linear1(F.dropout(x, p=0.5)))\n",
        "    x = F.relu(self.linear2(F.dropout(x, p=0.5)))\n",
        "\n",
        "    output = F.softmax(self.linear3(x), dim=1)\n",
        "    return output\n",
        "\n",
        "vgg = VGG16()\n",
        "summary(vgg, input_size=(10, 3, 224, 224), device='cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyxAwt4x2slx",
        "outputId": "b737cfd7-4422-462b-e490-a945642206e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG16                                    [10, 10]                  --\n",
              "├─Conv2d: 1-1                            [10, 64, 224, 224]        1,792\n",
              "├─Conv2d: 1-2                            [10, 64, 224, 224]        36,928\n",
              "├─MaxPool2d: 1-3                         [10, 64, 112, 112]        --\n",
              "├─Conv2d: 1-4                            [10, 128, 112, 112]       73,856\n",
              "├─Conv2d: 1-5                            [10, 128, 112, 112]       147,584\n",
              "├─MaxPool2d: 1-6                         [10, 128, 56, 56]         --\n",
              "├─Conv2d: 1-7                            [10, 256, 56, 56]         295,168\n",
              "├─Conv2d: 1-8                            [10, 256, 56, 56]         590,080\n",
              "├─Conv2d: 1-9                            [10, 256, 56, 56]         590,080\n",
              "├─MaxPool2d: 1-10                        [10, 256, 28, 28]         --\n",
              "├─Conv2d: 1-11                           [10, 512, 28, 28]         1,180,160\n",
              "├─Conv2d: 1-12                           [10, 512, 28, 28]         2,359,808\n",
              "├─Conv2d: 1-13                           [10, 512, 28, 28]         2,359,808\n",
              "├─MaxPool2d: 1-14                        [10, 512, 14, 14]         --\n",
              "├─Conv2d: 1-15                           [10, 512, 14, 14]         2,359,808\n",
              "├─Conv2d: 1-16                           [10, 512, 14, 14]         2,359,808\n",
              "├─Conv2d: 1-17                           [10, 512, 14, 14]         2,359,808\n",
              "├─MaxPool2d: 1-18                        [10, 512, 7, 7]           --\n",
              "├─Linear: 1-19                           [10, 4096]                102,764,544\n",
              "├─Linear: 1-20                           [10, 4096]                16,781,312\n",
              "├─Linear: 1-21                           [10, 10]                  40,970\n",
              "==========================================================================================\n",
              "Total params: 134,301,514\n",
              "Trainable params: 134,301,514\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 154.80\n",
              "==========================================================================================\n",
              "Input size (MB): 6.02\n",
              "Forward/backward pass size (MB): 1084.46\n",
              "Params size (MB): 537.21\n",
              "Estimated Total Size (MB): 1627.68\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算LeNet5以及AlexNet各层的感受野的大小\n",
        "!pip install torchinfo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torchinfo import summary\n",
        "\n",
        "data = torch.ones(size=(10, 1, 32, 32))\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.tanh(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = self.tanh(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    x = F.tanh(self.fc1(x))\n",
        "    output = F.softmax(self.fc2(x), dim=1)\n",
        "    output = F.softmax(x.view(-1, 16*5*5), dim=1)\n",
        "    \n",
        "net = LeNet5()"
      ],
      "metadata": {
        "id": "tOvnS2bcMiF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60b07a5-d19e-48e8-e40d-e791d6dc0e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算卷积层中参数的数量\n",
        "conv1 = nn.Conv2d(3, 6, 3)\n",
        "conv2 = nn.Conv2d(6, 4, 3)\n",
        "\n",
        "print(conv1.weight.numel())\n",
        "print(conv1.bias.numel())\n",
        "print(conv2.weight.numel())\n",
        "print(conv2.bias.numel())\n",
        "\n",
        "conv3 = nn.Conv2d(4, 16, 5, stride=2, padding=1) #(5*5*4)*16+16\n",
        "conv4 = nn.Conv2d(16, 3, 5, stride=3, padding=2) #(5*5*16)*3+3\n",
        "print(conv3.weight.numel())\n",
        "print(conv4.weight.numel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_xaelCxu4sr",
        "outputId": "d3dbf3c3-7382-475d-a103-2e6343246e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162\n",
            "6\n",
            "216\n",
            "4\n",
            "1600\n",
            "1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用nn.Sequential\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "data = torch.ones(size=(10, 3, 229, 229))\n",
        "# 不使用类，直接将需要串联的网络、函数等信息写在一个‘序列'里面\n",
        "net = nn.Sequential(nn.Conv2d(3, 6, 3), nn.ReLU(inplace=True),\n",
        "           nn.Conv2d(6, 4, 3), nn.ReLU(inplace=True),\n",
        "           nn.MaxPool2d(2),\n",
        "           nn.Conv2d(4, 16, 5, stride=2, padding=1), nn.ReLU(inplace=True),\n",
        "           nn.Conv2d(16, 3, 5, stride=3, padding=2), nn.ReLU(inplace=True),\n",
        "           nn.MaxPool2d(2))\n",
        "\n",
        "net(data).shape"
      ],
      "metadata": {
        "id": "4sx5qU2-w9r7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3a1ba9-cba1-4c26-9588-5c71bc18a54f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 9, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用nn.Sequential复现VGG16\n",
        "!pip install torchinfo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "class VGG16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.features_ = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    \n",
        "                    nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    \n",
        "                    nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    \n",
        "                    nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    \n",
        "                    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                    nn.MaxPool2d(2))\n",
        "    \n",
        "    self.clf_ = nn.Sequential(nn.Dropout(0.5),\n",
        "                  nn.Linear(512*7*7, 4096), nn.ReLU(inplace=True),\n",
        "                  nn.Dropout(0.5),\n",
        "                  nn.Linear(4096, 4096), nn.ReLU(inplace=True),\n",
        "                  nn.Linear(4096, 1000), nn.Softmax(dim=1))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.features_(x)\n",
        "    x = x.view(-1, 512*7*7)\n",
        "    output = self.clf_(x)\n",
        "    return output\n",
        "\n",
        "vgg = VGG16()\n",
        "summary(vgg, input_size=(10, 3, 224, 224), device='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYuppuEA7por",
        "outputId": "e9dae6aa-1a1d-4b1f-bdb1-517d33bbe3bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG16                                    [10, 1000]                --\n",
              "├─Sequential: 1-1                        [10, 512, 7, 7]           --\n",
              "│    └─Conv2d: 2-1                       [10, 64, 224, 224]        1,792\n",
              "│    └─ReLU: 2-2                         [10, 64, 224, 224]        --\n",
              "│    └─Conv2d: 2-3                       [10, 64, 224, 224]        36,928\n",
              "│    └─ReLU: 2-4                         [10, 64, 224, 224]        --\n",
              "│    └─MaxPool2d: 2-5                    [10, 64, 112, 112]        --\n",
              "│    └─Conv2d: 2-6                       [10, 128, 112, 112]       73,856\n",
              "│    └─ReLU: 2-7                         [10, 128, 112, 112]       --\n",
              "│    └─Conv2d: 2-8                       [10, 128, 112, 112]       147,584\n",
              "│    └─ReLU: 2-9                         [10, 128, 112, 112]       --\n",
              "│    └─MaxPool2d: 2-10                   [10, 128, 56, 56]         --\n",
              "│    └─Conv2d: 2-11                      [10, 256, 56, 56]         295,168\n",
              "│    └─ReLU: 2-12                        [10, 256, 56, 56]         --\n",
              "│    └─Conv2d: 2-13                      [10, 256, 56, 56]         590,080\n",
              "│    └─ReLU: 2-14                        [10, 256, 56, 56]         --\n",
              "│    └─Conv2d: 2-15                      [10, 256, 56, 56]         590,080\n",
              "│    └─ReLU: 2-16                        [10, 256, 56, 56]         --\n",
              "│    └─MaxPool2d: 2-17                   [10, 256, 28, 28]         --\n",
              "│    └─Conv2d: 2-18                      [10, 512, 28, 28]         1,180,160\n",
              "│    └─ReLU: 2-19                        [10, 512, 28, 28]         --\n",
              "│    └─Conv2d: 2-20                      [10, 512, 28, 28]         2,359,808\n",
              "│    └─ReLU: 2-21                        [10, 512, 28, 28]         --\n",
              "│    └─Conv2d: 2-22                      [10, 512, 28, 28]         2,359,808\n",
              "│    └─ReLU: 2-23                        [10, 512, 28, 28]         --\n",
              "│    └─MaxPool2d: 2-24                   [10, 512, 14, 14]         --\n",
              "│    └─Conv2d: 2-25                      [10, 512, 14, 14]         2,359,808\n",
              "│    └─ReLU: 2-26                        [10, 512, 14, 14]         --\n",
              "│    └─Conv2d: 2-27                      [10, 512, 14, 14]         2,359,808\n",
              "│    └─ReLU: 2-28                        [10, 512, 14, 14]         --\n",
              "│    └─Conv2d: 2-29                      [10, 512, 14, 14]         2,359,808\n",
              "│    └─ReLU: 2-30                        [10, 512, 14, 14]         --\n",
              "│    └─MaxPool2d: 2-31                   [10, 512, 7, 7]           --\n",
              "├─Sequential: 1-2                        [10, 1000]                --\n",
              "│    └─Dropout: 2-32                     [10, 25088]               --\n",
              "│    └─Linear: 2-33                      [10, 4096]                102,764,544\n",
              "│    └─ReLU: 2-34                        [10, 4096]                --\n",
              "│    └─Dropout: 2-35                     [10, 4096]                --\n",
              "│    └─Linear: 2-36                      [10, 4096]                16,781,312\n",
              "│    └─ReLU: 2-37                        [10, 4096]                --\n",
              "│    └─Linear: 2-38                      [10, 1000]                4,097,000\n",
              "│    └─Softmax: 2-39                     [10, 1000]                --\n",
              "==========================================================================================\n",
              "Total params: 138,357,544\n",
              "Trainable params: 138,357,544\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 154.84\n",
              "==========================================================================================\n",
              "Input size (MB): 6.02\n",
              "Forward/backward pass size (MB): 1084.54\n",
              "Params size (MB): 553.43\n",
              "Estimated Total Size (MB): 1643.99\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NiN网络的复现\n",
        "!pip install torchinfo\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "\n",
        "data = torch.ones(size=(10, 3, 32, 32))\n",
        "\n",
        "class NiN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.block1 = nn.Sequential(nn.Conv2d(3, 192, 5, padding=2), nn.ReLU(inplace=True),\n",
        "                   nn.Conv2d(192, 160, 1), nn.ReLU(inplace=True),\n",
        "                   nn.Conv2d(160, 96, 1), nn.ReLU(inplace=True),\n",
        "                   nn.MaxPool2d(3, stride=2),\n",
        "                   nn.Dropout(0.25))\n",
        "    \n",
        "    self.block2 = nn.Sequential(nn.Conv2d(96, 192, 5, padding=2), nn.ReLU(inplace=True),\n",
        "                   nn.Conv2d(192, 192, 1), nn.ReLU(inplace=True),\n",
        "                   nn.Conv2d(192, 192, 1), nn.ReLU(inplace=True),\n",
        "                   nn.MaxPool2d(3, stride=2), \n",
        "                   nn.Dropout(0.25))\n",
        "    \n",
        "    self.block3 = nn.Sequential(nn.Conv2d(192, 192, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                   nn.Conv2d(192, 192, 1), nn.ReLU(inplace=True),\n",
        "                   nn.Conv2d(192, 10, 1), nn.ReLU(inplace=True),\n",
        "                   nn.AvgPool2d(7, stride=1),\n",
        "                   nn.Softmax(dim=1))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    output = self.block3(self.block2(self.block1(x)))\n",
        "    return output\n",
        "\n",
        "net = NiN()\n",
        "net(data).shape\n",
        "summary(net, input_size=(10, 3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g1Hua3JNfN5",
        "outputId": "1f6a648d-6710-4e5c-cce5-8ea3e69bc68c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "NiN                                      [10, 10, 1, 1]            --\n",
              "├─Sequential: 1-1                        [10, 96, 15, 15]          --\n",
              "│    └─Conv2d: 2-1                       [10, 192, 32, 32]         14,592\n",
              "│    └─ReLU: 2-2                         [10, 192, 32, 32]         --\n",
              "│    └─Conv2d: 2-3                       [10, 160, 32, 32]         30,880\n",
              "│    └─ReLU: 2-4                         [10, 160, 32, 32]         --\n",
              "│    └─Conv2d: 2-5                       [10, 96, 32, 32]          15,456\n",
              "│    └─ReLU: 2-6                         [10, 96, 32, 32]          --\n",
              "│    └─MaxPool2d: 2-7                    [10, 96, 15, 15]          --\n",
              "│    └─Dropout: 2-8                      [10, 96, 15, 15]          --\n",
              "├─Sequential: 1-2                        [10, 192, 7, 7]           --\n",
              "│    └─Conv2d: 2-9                       [10, 192, 15, 15]         460,992\n",
              "│    └─ReLU: 2-10                        [10, 192, 15, 15]         --\n",
              "│    └─Conv2d: 2-11                      [10, 192, 15, 15]         37,056\n",
              "│    └─ReLU: 2-12                        [10, 192, 15, 15]         --\n",
              "│    └─Conv2d: 2-13                      [10, 192, 15, 15]         37,056\n",
              "│    └─ReLU: 2-14                        [10, 192, 15, 15]         --\n",
              "│    └─MaxPool2d: 2-15                   [10, 192, 7, 7]           --\n",
              "│    └─Dropout: 2-16                     [10, 192, 7, 7]           --\n",
              "├─Sequential: 1-3                        [10, 10, 1, 1]            --\n",
              "│    └─Conv2d: 2-17                      [10, 192, 7, 7]           331,968\n",
              "│    └─ReLU: 2-18                        [10, 192, 7, 7]           --\n",
              "│    └─Conv2d: 2-19                      [10, 192, 7, 7]           37,056\n",
              "│    └─ReLU: 2-20                        [10, 192, 7, 7]           --\n",
              "│    └─Conv2d: 2-21                      [10, 10, 7, 7]            1,930\n",
              "│    └─ReLU: 2-22                        [10, 10, 7, 7]            --\n",
              "│    └─AvgPool2d: 2-23                   [10, 10, 1, 1]            --\n",
              "│    └─Softmax: 2-24                     [10, 10, 1, 1]            --\n",
              "==========================================================================================\n",
              "Total params: 966,986\n",
              "Trainable params: 966,986\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 2.01\n",
              "==========================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 48.61\n",
              "Params size (MB): 3.87\n",
              "Estimated Total Size (MB): 52.60\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Pytorch深度学习10-构筑卷积神经网络.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGiTkadRd9HaiXWLXM+mEb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}