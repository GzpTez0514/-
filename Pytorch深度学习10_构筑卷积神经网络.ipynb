{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GzpTez0514/-/blob/main/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A010_%E6%9E%84%E7%AD%91%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzkK_G7AVgaO",
        "outputId": "2a6d728c-fc2d-4fb0-d50e-9859057a6eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 6, 26, 26])\n",
            "torch.Size([10, 4, 24, 24])\n"
          ]
        }
      ],
      "source": [
        "# 卷积层\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "data = torch.ones(size=(10, 3, 28, 28)) # 10张尺寸为28*28的，拥有3个通道的图像\n",
        "conv1 = nn.Conv2d(in_channels=3, \n",
        "          out_channels=6, # 全部通道的扫描值被合并，6个卷积核形成6个feature map\n",
        "          kernel_size=3 # 表示3x3的卷积核\n",
        "          )\n",
        "\n",
        "conv2 = nn.Conv2d(in_channels=6, # 对下一层网络来说，输入的是上层生成的6个feature map\n",
        "          out_channels=4, # 全部特征图的扫描值被合并，4个卷积核形成4个新的feature map\n",
        "          kernel_size=3)\n",
        "\n",
        "print(conv1(data).shape)\n",
        "print(conv2(conv1(data)).shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFgCfH5zWkKU"
      },
      "outputs": [],
      "source": [
        "# 特征图的尺寸 （H + 2P -K）/ S + 1\n",
        "data = torch.ones(size=(10, 3, 28, 28))\n",
        "conv1 = nn.Conv2d(3, 6, 3)\n",
        "conv2 = nn.Conv2d(6, 4, 3)\n",
        "conv3 = nn.Conv2d(4, 16, 5, stride=2, padding=1) \n",
        "conv4 = nn.Conv2d(16, 3, 5, stride=3, padding=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16的复现\n",
        "# (卷积x2 + 池化) x2 -> (卷积x3 + 池化) x3 —> FC层x3 每组卷积+池化算一个block\n",
        "!pip install torchinfo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torchinfo import summary\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # block1\n",
        "    self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # block2\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # block3\n",
        "    self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "    self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "    self.conv7 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "    self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # block4\n",
        "    self.conv8 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "    self.conv9 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.conv10 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # block5\n",
        "    self.conv11 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.conv13 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "    self.pool5 = nn.MaxPool2d(2,2)\n",
        "\n",
        "    # FC层\n",
        "    self.linear1 = nn.Linear(512*7*7, 4096)\n",
        "    self.linear2 = nn.Linear(4096, 4096)\n",
        "    self.linear3 = nn.Linear(4096, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.pool2(x)\n",
        "\n",
        "    x = F.relu(self.conv5(x))\n",
        "    x = F.relu(self.conv6(x))\n",
        "    x = F.relu(self.conv7(x))\n",
        "    x = self.pool3(x)\n",
        "\n",
        "    x = F.relu(self.conv8(x))\n",
        "    x = F.relu(self.conv9(x))\n",
        "    x = F.relu(self.conv10(x))\n",
        "    x = self.pool4(x)\n",
        "\n",
        "    x = F.relu(self.conv11(x))\n",
        "    x = F.relu(self.conv12(x))\n",
        "    x = F.relu(self.conv13(x))\n",
        "    x = self.pool5(x)\n",
        "    \n",
        "    x = x.view(-1, 512*7*7)\n",
        "\n",
        "    x = F.relu(self.linear1(F.dropout(x, p=0.5)))\n",
        "    x = F.relu(self.linear2(F.dropout(x, p=0.5)))\n",
        "\n",
        "    output = F.softmax(self.linear3(x), dim=1)\n",
        "    return output\n",
        "\n",
        "vgg = VGG16()\n",
        "summary(vgg, input_size=(10, 3, 224, 224), device='cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyxAwt4x2slx",
        "outputId": "b737cfd7-4422-462b-e490-a945642206e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG16                                    [10, 10]                  --\n",
              "├─Conv2d: 1-1                            [10, 64, 224, 224]        1,792\n",
              "├─Conv2d: 1-2                            [10, 64, 224, 224]        36,928\n",
              "├─MaxPool2d: 1-3                         [10, 64, 112, 112]        --\n",
              "├─Conv2d: 1-4                            [10, 128, 112, 112]       73,856\n",
              "├─Conv2d: 1-5                            [10, 128, 112, 112]       147,584\n",
              "├─MaxPool2d: 1-6                         [10, 128, 56, 56]         --\n",
              "├─Conv2d: 1-7                            [10, 256, 56, 56]         295,168\n",
              "├─Conv2d: 1-8                            [10, 256, 56, 56]         590,080\n",
              "├─Conv2d: 1-9                            [10, 256, 56, 56]         590,080\n",
              "├─MaxPool2d: 1-10                        [10, 256, 28, 28]         --\n",
              "├─Conv2d: 1-11                           [10, 512, 28, 28]         1,180,160\n",
              "├─Conv2d: 1-12                           [10, 512, 28, 28]         2,359,808\n",
              "├─Conv2d: 1-13                           [10, 512, 28, 28]         2,359,808\n",
              "├─MaxPool2d: 1-14                        [10, 512, 14, 14]         --\n",
              "├─Conv2d: 1-15                           [10, 512, 14, 14]         2,359,808\n",
              "├─Conv2d: 1-16                           [10, 512, 14, 14]         2,359,808\n",
              "├─Conv2d: 1-17                           [10, 512, 14, 14]         2,359,808\n",
              "├─MaxPool2d: 1-18                        [10, 512, 7, 7]           --\n",
              "├─Linear: 1-19                           [10, 4096]                102,764,544\n",
              "├─Linear: 1-20                           [10, 4096]                16,781,312\n",
              "├─Linear: 1-21                           [10, 10]                  40,970\n",
              "==========================================================================================\n",
              "Total params: 134,301,514\n",
              "Trainable params: 134,301,514\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 154.80\n",
              "==========================================================================================\n",
              "Input size (MB): 6.02\n",
              "Forward/backward pass size (MB): 1084.46\n",
              "Params size (MB): 537.21\n",
              "Estimated Total Size (MB): 1627.68\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tOvnS2bcMiF0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Pytorch深度学习10-构筑卷积神经网络.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxir9wIhHYZN9ygWs0WqZm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}